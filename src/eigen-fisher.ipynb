{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "import random, os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face and eyes detection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(image):\n",
    "    #image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haar_classifier = cv2.CascadeClassifier('C:/Users/Thomas/Documents/face_detection/haarcascades/haarcascade_frontalface_default.xml')\n",
    "    face = haar_classifier.detectMultiScale(image,minNeighbors=6,minSize=(75, 75)) #parameters change depending the dataset\n",
    "    if (len(face)==1): #if 1 face is found\n",
    "        (x,y,w,h) = face[0]\n",
    "        return True, image[y:y+w, x:x+h], face[0]\n",
    "    elif (len(face)==0): #if no faces are detected\n",
    "        \n",
    "        return False, \"zero\"\n",
    "    else: #if more than 1 faces are detected, the biggest is kept (the smaller ones usually belong in the background)\n",
    "        biggest=0\n",
    "        pos=0\n",
    "        for i,(x,y,w,h) in enumerate(face):\n",
    "            if biggest<(h*w):\n",
    "                biggest=h*w\n",
    "                pos=i\n",
    "        return True, image[y:y+w, x:x+h], face[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(image):\n",
    "    #image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haar_classifier = cv2.CascadeClassifier('C:/Users/Thomas/Documents/face_detection/haarcascades/haarcascade_frontalface_default.xml')\n",
    "    face = haar_classifier.detectMultiScale(image)#,scaleFactor=1.2, minNeighbors=5)\n",
    "    if (len(face)==1): #if 1 face is found\n",
    "        (x,y,w,h) = face[0]\n",
    "        '''\n",
    "        for (x,y,w,h) in face: \n",
    "            cv2.rectangle(image, (x,y), (x+w,y+h), (255,255,255), 3)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        '''\n",
    "        return True, image[y:y+w, x:x+h], face[0]\n",
    "    elif (len(face)==0): #if no faces are detected\n",
    "        return False, \"zero\"\n",
    "    else: #if more than 1 faces are detected\n",
    "        return False, \"more\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_detection(image):\n",
    "    #image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image=cv2.resize(image, (200, 200), interpolation=cv2.INTER_LINEAR)\n",
    "    haar_classifier = cv2.CascadeClassifier('C:/Users/Thomas/Documents/face_detection/haarcascades/haarcascade_eye.xml')\n",
    "    eyes = haar_classifier.detectMultiScale(image, minNeighbors=4)#, minSize=(30, 30))\n",
    "    if (len(eyes)==2): #if 2 eyes are detected\n",
    "        #(x,y,w,h) = face[0]\n",
    "        return True, eyes\n",
    "    else:      #if the number of eyes found is different from 2\n",
    "        return False, \"more or less\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath=('C:/Users/Thomas/Documents/Datasets/lfw(250x250)/')\n",
    "min_faces=30\n",
    "faces=[]\n",
    "labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some counters\n",
    "photos_with_face=0\n",
    "photos_with_0_faces=0\n",
    "photos_with_more_faces=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some more counters\n",
    "photos_with_2_eyes=0\n",
    "photos_with__eyes=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the data/images and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=[]  #all the names are saved here\n",
    "total_photos_seen=0 \n",
    "n_classes=0\n",
    "folders = os.listdir(datapath)\n",
    "for folder in folders:\n",
    "    label = os.path.basename(folder)\n",
    "    training_images_path = datapath + '/' + folder\n",
    "    num_of_faces = len(os.listdir(training_images_path))\n",
    "    #if num_of_faces>=min_faces:   #people with low number of faces are skipped\n",
    "    target_names.append(label)\n",
    "    n_classes=n_classes+1\n",
    "    faces_per_person=0\n",
    "    for image in os.listdir(training_images_path):\n",
    "        total_photos_seen=total_photos_seen+1\n",
    "        image_path = training_images_path + '/' + image\n",
    "        training_image = cv2.imread(image_path)\n",
    "        #face=cv2.cvtColor(training_image,cv2.COLOR_BGR2GRAY)\n",
    "        #resized=cv2.resize(face,(224,224),interpolation=cv2.INTER_AREA)\n",
    "        result_im=face_detection(training_image) #this function returns TRUE/FALSE, the cut image and the coordinates of where the cut was made\n",
    "        if result_im[0]: #if TRUE (face detected) then the cut face goes into the array\n",
    "            cut_face=result_im[1]\n",
    "            faces.append(cut_face)\n",
    "            labels.append(n_classes)\n",
    "\n",
    "        '''\n",
    "        if faces_per_person==45:\n",
    "                break\n",
    "        '''        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_faces=[]\n",
    "new_labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_faces=0\n",
    "#unwanted_images=[3,110,113,166,238,245,349,398,444,903,978,1194,1218] \n",
    "for i in range(len(faces)):\n",
    "    #if i not in unwanted_images: in case there are pictures that cannot be processed\n",
    "    training_image = cv2.imread(faces[i])\n",
    "    result_im=eye_detection(training_image) #finding the place of the eyes\n",
    "    \n",
    "    if result_im[0]: #process of finding the angle of the two eyes, and alighnment\n",
    "        rotated_faces=rotated_faces+1\n",
    "        (x1,y1,w1,h1)=result_im[1][0]\n",
    "        (x2,y2,w2,h2)=result_im[1][1]\n",
    "        eye1_center_x=x1+(w1/2)\n",
    "        eye1_center_y=y1+(h1/2)\n",
    "        eye2_center_x=x2+(w2/2)\n",
    "        eye2_center_y=y2+(h2/2)\n",
    "        if (eye1_center_x>eye2_center_y):\n",
    "            deltaY = eye1_center_y - eye2_center_y \n",
    "            deltaX = eye1_center_x - eye2_center_x\n",
    "        else:\n",
    "            deltaY = eye2_center_y - eye1_center_y \n",
    "            deltaX = eye2_center_x - eye1_center_x\n",
    "            \n",
    "        my_radians = math.atan2(deltaY , deltaX)\n",
    "        my_degrees = math.degrees(my_radians)\n",
    "\n",
    "        #rotation\n",
    "        rows, cols = training_image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((cols/2, rows/2), my_degrees, 1)\n",
    "        img_rotated = cv2.warpAffine(training_image, M, (cols,rows))\n",
    "        '''\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        plt.text(0,0,i)\n",
    "        plt.imshow(img_rotated)\n",
    "        plt.show()\n",
    "        '''\n",
    "\n",
    "        #scaling (all images will become 200x200)\n",
    "        #if before the conversion the image is smaller than 200x200 INTER_LINEAR will be used, else INTER_AREA will be used\n",
    "        image_size=rows*cols        \n",
    "        if (image_size<=40000):\n",
    "            scaled_image=cv2.resize(img_rotated, (200, 200), interpolation=cv2.INTER_LINEAR)\n",
    "        else:\n",
    "            scaled_image=cv2.resize(img_rotated, (200, 200), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        #normalization\n",
    "        norm_img = np.zeros((200, 200))\n",
    "        norm_img = cv2.normalize(scaled_image, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "        final_image = cv2.cvtColor(norm_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        new_faces.append(final_image)\n",
    "        new_labels.append(labels[i])\n",
    "\n",
    "faces=new_faces\n",
    "labels=new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the components parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"flattening\" the faces for the PCA\n",
    "flat_faces = []\n",
    "\n",
    "for face in faces:\n",
    "    flat_faces.append(face.reshape(-1))\n",
    "\n",
    "flat_faces = np.array(flat_faces)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(flat_faces, labels, test_size=0.1, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Firstly, PCA is fitted without the component parameter, so we can find the optimal number of components\n",
    "t0=time()\n",
    "pca = PCA().fit(X_train)\n",
    "\n",
    "plt.figure(figsize=(18, 7))\n",
    "plt.plot(pca.explained_variance_ratio_.cumsum(), lw=3)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the smallest value is the optimal number of components\n",
    "np.where(pca.explained_variance_ratio_.cumsum() > 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import DotProduct\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:  # Python 3.x\n",
    "    import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('eigen.p', 'rb') as fp:\n",
    "#    data = pickle.load(fp)\n",
    "#open a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of components\n",
    "#small dataset 42\n",
    "#bioID 139 (preprocessed 140)\n",
    "#facescrub 289(250x250),312(500x500),301(350x350), 270(200x200) 251 (preprocessed)\n",
    "#lfw 374 (preprocessed 210)\n",
    "#lfwcropped  158\n",
    "#lfw2 (preprocessed 210)\n",
    "#extended 142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=142, svd_solver='randomized',whiten=True)\n",
    "lda = LDA()\n",
    "cv=StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy': 'accuracy',\n",
    "           'precision_macro': 'precision_macro',\n",
    "           'precision_micro': 'precision_micro',\n",
    "           'precision_weighted': 'precision_weighted',\n",
    "           'recall_macro': 'recall_macro',\n",
    "           'recall_micro': 'recall_micro',\n",
    "           'recall_weighted': 'recall_weighted',           \n",
    "           'f1_macro':'f1_macro',\n",
    "           'f1_micro':'f1_micro',\n",
    "           'f1_weighted':'f1_weighted'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the dictionaries will be filled with the results, and then the dictionaries will be saved in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eigen = dict({'svc':[],'mlp':[],'knn':[],'logreg':[],'linsvc':[],'tree':[],'forrest':[],'adaboost':[],'gnb':[],'gpc':[],'ridge':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fisher = dict({'svc':[],'mlp':[],'knn':[],'logreg':[],'linsvc':[],'tree':[],'forrest':[],'adaboost':[],'gnb':[],'gpc':[],'ridge':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenfaces_learning_curve=dict({'svc':None,'mlp':None,'knn':None,'logreg':None,'linsvc':None,\n",
    "                                'tree':None,'forrest':None,'adaboost':None,'gnb':None,'gpc':None,'ridge':None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisherfaces_learning_curve=dict({'svc':None,'mlp':None,'knn':None,'logreg':None,'linsvc':None,\n",
    "                                'tree':None,'forrest':None,'adaboost':None,'gnb':None,'gpc':None,'ridge':None})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=SVC(class_weight='balanced',C=28.104130383007977,gamma=7.281641758356972,kernel='poly',degree=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "svm_score=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eigen['svc']=svm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "svc_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "eigenfaces_learning_curve['svc']=svc_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3,p=2,leaf_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                ('knn', knn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "knn_score=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eigen['knn']=knn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "knn_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "eigenfaces_learning_curve['knn']=knn_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='adam',hidden_layer_sizes=(333,200,496,347,495),alpha=0.08193742846113258,\n",
    "                    learning_rate='invscaling', activation='tanh',momentum=0.5725450935194276,verbose=False, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                ('mlp', mlp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "mlp_score=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eigen['mlp']=mlp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "mlp_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "eigenfaces_learning_curve['mlp']=mlp_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(class_weight='balanced',C=33.60545334855496,solver='sag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                ('logreg', logreg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "logreg_score=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eigen['logreg']=logreg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "logreg_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "eigenfaces_learning_curve['logreg']=logreg_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linearsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm = LinearSVC(C=95.48139914999754,loss='hinge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                ('linear_svm', linear_svm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "linsvc_score=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eigen['linsvc']=linsvc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "linsvc_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "eigenfaces_learning_curve['linsvc']=linsvc_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=0,min_samples_leaf=1,max_depth=15,min_impurity_decrease=0.021318938975762092,criterion='entropy',max_features=10,\n",
    "                              max_leaf_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                ('tree', tree)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "tree_score=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eigen['tree']=tree_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "tree_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "eigenfaces_learning_curve['tree']=tree_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest = RandomForestClassifier(random_state=0,min_samples_leaf=3,max_depth=10,n_estimators=387,class_weight='balanced',bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                ('forrest', forrest)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "forrest_score=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eigen['forrest']=forrest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "forrest_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "eigenfaces_learning_curve['forrest']=forrest_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = AdaBoostClassifier(n_estimators=264,random_state=0,learning_rate=0.2131171118825734)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                ('adaboost', adaboost)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "ada_score=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eigen['adaboost']=ada_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "adaboost_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "eigenfaces_learning_curve['adaboost']=adaboost_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                ('gnb', gnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "gnb_score=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eigen['gnb']=gnb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "gnb_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "eigenfaces_learning_curve['gnb']=gnb_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gaussian process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpc = GaussianProcessClassifier(kernel=1.0*RBF(length_scale=0.840398547098756),random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                ('gpc', gpc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "gpc_score=cross_validate(pipe, flat_faces, labels, cv=cv_for_gpc,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eigen['gpc']=gpc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv_for_gpc,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "gpc_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "eigenfaces_learning_curve['gpc']=gpc_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                ('ridge', ridge)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "ridge_score=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_eigen['ridge']=ridge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "ridge_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "eigenfaces_learning_curve['ridge']=ridge_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving data in pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eigenfaces_extyale.p', 'wb') as fp:\n",
    "    pickle.dump(results_eigen, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eigenfaces_learning_curve_extyale.p', 'wb') as fp:\n",
    "    pickle.dump(eigenfaces_learning_curve, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fisherfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(kernel='linear', class_weight='balanced',C=3.9241808801638385,gamma=96.58400875342846,degree=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda',lda),\n",
    "                ('svc', svc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "svm_score_=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fisher['svc']=svm_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "svc_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "fisherfaces_learning_curve['svc']=svc_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=13,p=1,leaf_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda',lda),\n",
    "                ('knn', knn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "knn_score_=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fisher['knn']=knn_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "knn_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "fisherfaces_learning_curve['knn']=knn_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='adam',hidden_layer_sizes=(417,469,290,194),alpha=0.011508598976828089,\n",
    "                    learning_rate='constant', activation='tanh',momentum=0.5812137485951651,verbose=False, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda',lda),\n",
    "                ('mlp', mlp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "mlp_score_=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fisher['mlp']=mlp_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "mlp_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "fisherfaces_learning_curve['mlp']=mlp_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=26.23190488581573,solver='lbfgs',class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda',lda),\n",
    "                ('logreg', logreg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "logreg_score_=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fisher['logreg']=logreg_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "logreg_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "fisherfaces_learning_curve['logreg']=logreg_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linearsvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm = LinearSVC(C=0.851388416540332,loss='hinge',class_weight='balanced',fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda', lda),\n",
    "                ('linear_svm', linear_svm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "linsvc_score_=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fisher['linsvc']=linsvc_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "linsvc_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "fisherfaces_learning_curve['linsvc']=linsvc_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=0,criterion='gini',min_impurity_decrease=0.03861521502801396,max_depth=19,min_samples_leaf=2,max_leaf_nodes=None,max_features=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda',lda),\n",
    "                ('tree', tree)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "tree_score_=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fisher['tree']=tree_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "tree_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "fisherfaces_learning_curve['tree']=tree_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest = RandomForestClassifier(random_state=0,max_depth=9,min_samples_leaf=3,n_estimators=241,class_weight='balanced',bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda', lda),\n",
    "                ('forrest', forrest)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "forrest_score_=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fisher['forrest']=forrest_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "forrest_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "fisherfaces_learning_curve['forrest']=forrest_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = AdaBoostClassifier(n_estimators=174,random_state=0,learning_rate=0.28183708257574086)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda', lda),\n",
    "                ('adaboost', adaboost)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "ada_score_=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fisher['adaboost']=ada_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "adaboost_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "fisherfaces_learning_curve['adaboost']=adaboost_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gaussiannb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda', lda),\n",
    "                ('gnb', gnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "gnb_score_=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fisher['gnb']=gnb_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "gnb_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "fisherfaces_learning_curve['gnb']=gnb_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gaussian process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpc = GaussianProcessClassifier(kernel=1.0*RBF(length_scale=1.0687440294594166),random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline([('pca', pca),\n",
    "                ('lda',lda),\n",
    "                ('gpc', gpc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "gpc_score_=cross_validate(pipe, flat_faces, labels, cv=cv_for_gpc,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fisher['gpc']=gpc_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv_for_gpc,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "gpc_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "fisherfaces_learning_curve['gpc']=gpc_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = RidgeClassifier(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', pca),\n",
    "                ('lda',lda),\n",
    "                ('ridge', ridge)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "ridge_score_=cross_validate(pipe, flat_faces, labels, cv=cv,scoring=scoring,return_train_score=True,n_jobs=-1)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fisher['ridge']=ridge_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "train_sizes, train_scores, test_scores, fit_times, score_times =learning_curve(pipe, flat_faces, labels, n_jobs=4,\n",
    "                       cv=cv,train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                       return_times=True)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "ridge_learning_curve=dict({1:train_sizes,2:train_scores,3:test_scores,4:fit_times,5:score_times})\n",
    "fisherfaces_learning_curve['ridge']=ridge_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving data in pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fisher_extyale.p', 'wb') as fp:\n",
    "    pickle.dump(results_fisher, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fisher_learning_curve_extyale.p', 'wb') as fp:\n",
    "    pickle.dump(fisherfaces_learning_curve, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
