{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from random import seed\n",
    "from random import randrange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "from sklearn.metrics import confusion_matrix, classification_report,precision_score,f1_score,recall_score,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import DotProduct\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:  # Python 3.x\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face and eyes detection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(image):\n",
    "    #image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haar_classifier = cv2.CascadeClassifier('C:/Users/Thomas/Documents/face_detection/haarcascades/haarcascade_frontalface_default.xml')\n",
    "    face = haar_classifier.detectMultiScale(image,minNeighbors=6,minSize=(75, 75)) #oi parametroi allazoun analoga to dataset\n",
    "    if (len(face)==1): #if 1 face is found\n",
    "        (x,y,w,h) = face[0]\n",
    "        return True, image[y:y+w, x:x+h], face[0]\n",
    "    elif (len(face)==0): #if no faces are detected\n",
    "        \n",
    "        return False, \"zero\"\n",
    "    else:  #if more than 1 faces are detected, the biggest is kept (the smaller ones usually belong in the background)\n",
    "        biggest=0\n",
    "        pos=0\n",
    "        for i,(x,y,w,h) in enumerate(face):\n",
    "            if biggest<(h*w):\n",
    "                biggest=h*w\n",
    "                pos=i\n",
    "        return True, image[y:y+w, x:x+h], face[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(image):\n",
    "    #image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haar_classifier = cv2.CascadeClassifier('C:/Users/Thomas/Documents/face_detection/haarcascades/haarcascade_frontalface_default.xml')\n",
    "    face = haar_classifier.detectMultiScale(image)#,scaleFactor=1.2, minNeighbors=5)\n",
    "    if (len(face)==1): #if 1 face is found\n",
    "        (x,y,w,h) = face[0]\n",
    "        '''\n",
    "        for (x,y,w,h) in face: \n",
    "            cv2.rectangle(image, (x,y), (x+w,y+h), (255,255,255), 3)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        '''\n",
    "        return True, image[y:y+w, x:x+h], face[0]\n",
    "    elif (len(face)==0): #if no faces are detected\n",
    "        return False, \"zero\"\n",
    "    else: #if more than 1 faces are detected\n",
    "        return False, \"more\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_detection(image):\n",
    "    #image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haar_classifier = cv2.CascadeClassifier('C:/Users/Thomas/Documents/face_detection/haarcascades/haarcascade_eye.xml')\n",
    "    eyes = haar_classifier.detectMultiScale(image, minNeighbors=4, minSize=(30, 30))\n",
    "    if (len(eyes)==2): #if 2 eyes are detected\n",
    "        return True, eyes\n",
    "    else:\n",
    "        haar_classifier = cv2.CascadeClassifier('C:/Users/Thomas/Documents/face_detection/haarcascades/haarcascade_eye_tree_eyeglasses.xml')\n",
    "        glasses = haar_classifier.detectMultiScale(image)\n",
    "        if (len(glasses)==2):\n",
    "            return True, glasses\n",
    "        else:\n",
    "            return False, \"more or less\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'C:/Users/Thomas/Documents/Datasets/ExtYale(640x480)/'  \n",
    "training_names = os.listdir(train_path)\n",
    "min_faces=30\n",
    "scores=[]\n",
    "target_names=[]  #all the names are saved here\n",
    "\n",
    "faces=[]\n",
    "labels=[]\n",
    "\n",
    "total_photos_seen=0 \n",
    "n_classes=0\n",
    "folders = os.listdir(train_path)\n",
    "for folder in folders:\n",
    "    label = os.path.basename(folder)\n",
    "    training_images_path = train_path + '/' + folder\n",
    "    num_of_faces = len(os.listdir(training_images_path))\n",
    "    #if num_of_faces>=min_faces:   #people with low number of faces are skipped\n",
    "    target_names.append(label)\n",
    "    n_classes=n_classes+1\n",
    "    faces_per_person=0\n",
    "    for image in os.listdir(training_images_path):\n",
    "        total_photos_seen=total_photos_seen+1\n",
    "        image_path = training_images_path + '/' + image\n",
    "        training_image = cv2.imread(image_path)\n",
    "        #face=cv2.cvtColor(training_image,cv2.COLOR_BGR2GRAY)\n",
    "        #resized=cv2.resize(face,(224,224),interpolation=cv2.INTER_AREA)\n",
    "        result_im=face_detection(training_image) #this function returns TRUE/FALSE, the cut image and the coordinates of where the cut was made\n",
    "        if result_im[0]: #if TRUE (face detected) then the cut face goes into the array\n",
    "            cut_face=result_im[1]\n",
    "            faces.append(cut_face)\n",
    "            labels.append(n_classes)\n",
    "\n",
    "        '''\n",
    "        if faces_per_person==45:\n",
    "                break\n",
    "        '''       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_faces=[]\n",
    "new_labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_faces=0\n",
    "for i in range(len(faces)):\n",
    "    training_image = cv2.imread(faces[i])\n",
    "    result_im=eye_detection(training_image) #finding the place of the eyes\n",
    "    \n",
    "    if result_im[0]: #process of finding the angle of the two eyes, and alighnment\n",
    "        rotated_faces=rotated_faces+1\n",
    "        (x1,y1,w1,h1)=result_im[1][0]\n",
    "        (x2,y2,w2,h2)=result_im[1][1]\n",
    "        eye1_center_x=x1+(w1/2)\n",
    "        eye1_center_y=y1+(h1/2)\n",
    "        eye2_center_x=x2+(w2/2)\n",
    "        eye2_center_y=y2+(h2/2)\n",
    "        if (eye1_center_x>eye2_center_y):\n",
    "            deltaY = eye1_center_y - eye2_center_y \n",
    "            deltaX = eye1_center_x - eye2_center_x\n",
    "        else:\n",
    "            deltaY = eye2_center_y - eye1_center_y \n",
    "            deltaX = eye2_center_x - eye1_center_x\n",
    "        my_radians = math.atan2(deltaY , deltaX)\n",
    "        my_degrees = math.degrees(my_radians)\n",
    "\n",
    "        #rotation\n",
    "        rows, cols = training_image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((cols/2, rows/2), my_degrees, 1)\n",
    "        img_rotated = cv2.warpAffine(training_image, M, (cols,rows))\n",
    "        '''\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        plt.text(0,0,i)\n",
    "        plt.imshow(img_rotated)\n",
    "        plt.show()\n",
    "        '''\n",
    "\n",
    "        #scaling (all images will become 200x200)\n",
    "        #if before the conversion the image is smaller than 200x200 INTER_LINEAR will be used, else INTER_AREA will be used\n",
    "        image_size=rows*cols        \n",
    "        if (image_size<=40000):\n",
    "            scaled_image=cv2.resize(img_rotated, (200, 200), interpolation=cv2.INTER_LINEAR)\n",
    "        else:\n",
    "            scaled_image=cv2.resize(img_rotated, (200, 200), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        #normalization\n",
    "        norm_img = np.zeros((200, 200))\n",
    "        norm_img = cv2.normalize(scaled_image, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "        final_image = cv2.cvtColor(norm_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        new_faces.append(final_image)\n",
    "        new_labels.append(labels[i])\n",
    "        \n",
    "faces=new_faces\n",
    "labels=new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = dict({'svc':None,'mlp':None,'knn':None,'logreg':None,'linsvc':None,'tree':None,'forrest':None,'adaboost':None,'gnb':None,'gpc':None,'ridge':None})\n",
    "brisk = dict({'svc':None,'mlp':None,'knn':None,'logreg':None,'linsvc':None,'tree':None,'forrest':None,'adaboost':None,'gnb':None,'gpc':None,'ridge':None})\n",
    "sift = dict({'svc':None,'mlp':None,'knn':None,'logreg':None,'linsvc':None,'tree':None,'forrest':None,'adaboost':None,'gnb':None,'gpc':None,'ridge':None})\n",
    "surf = dict({'svc':None,'mlp':None,'knn':None,'logreg':None,'linsvc':None,'tree':None,'forrest':None,'adaboost':None,'gnb':None,'gpc':None,'ridge':None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_learning_curve = dict({'svc':None,'mlp':None,'knn':None,'logreg':None,'linsvc':None,'tree':None,'forrest':None,'adaboost':None,'gnb':None,'gpc':None,'ridge':None})\n",
    "brisk_learning_curve = dict({'svc':None,'mlp':None,'knn':None,'logreg':None,'linsvc':None,'tree':None,'forrest':None,'adaboost':None,'gnb':None,'gpc':None,'ridge':None})\n",
    "sift_learning_curve = dict({'svc':None,'mlp':None,'knn':None,'logreg':None,'linsvc':None,'tree':None,'forrest':None,'adaboost':None,'gnb':None,'gpc':None,'ridge':None})\n",
    "surf_learning_curve = dict({'svc':None,'mlp':None,'knn':None,'logreg':None,'linsvc':None,'tree':None,'forrest':None,'adaboost':None,'gnb':None,'gpc':None,'ridge':None})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_sizes1=np.empty(5)\n",
    "train_sizes1[:]=np.NaN\n",
    "train_scores1=np.empty([5, 10])\n",
    "train_scores1[:]=np.NaN\n",
    "test_scores1=np.empty([5, 10])\n",
    "test_scores1[:]=np.NaN\n",
    "fit_times1=np.empty([5, 10])\n",
    "fit_times1[:]=np.NaN\n",
    "score_times1=np.empty([5, 10])\n",
    "score_times1[:]=np.NaN\n",
    "cluster_times1=np.empty([5, 10])\n",
    "cluster_times1[:]=np.NaN\n",
    "\n",
    "train_sizes2=np.empty(5)\n",
    "train_sizes2[:]=np.NaN\n",
    "train_scores2=np.empty([5, 10])\n",
    "train_scores2[:]=np.NaN\n",
    "test_scores2=np.empty([5, 10])\n",
    "test_scores2[:]=np.NaN\n",
    "fit_times2=np.empty([5, 10])\n",
    "fit_times2[:]=np.NaN\n",
    "score_times2=np.empty([5, 10])\n",
    "score_times2[:]=np.NaN\n",
    "cluster_times2=np.empty([5, 10])\n",
    "cluster_times2[:]=np.NaN\n",
    "\n",
    "train_sizes3=np.empty(5)\n",
    "train_sizes3[:]=np.NaN\n",
    "train_scores3=np.empty([5, 10])\n",
    "train_scores3[:]=np.NaN\n",
    "test_scores3=np.empty([5, 10])\n",
    "test_scores3[:]=np.NaN\n",
    "fit_times3=np.empty([5, 10])\n",
    "fit_times3[:]=np.NaN\n",
    "score_times3=np.empty([5, 10])\n",
    "score_times3[:]=np.NaN\n",
    "cluster_times3=np.empty([5, 10])\n",
    "cluster_times3[:]=np.NaN\n",
    "\n",
    "train_sizes4=np.empty(5)\n",
    "train_sizes4[:]=np.NaN\n",
    "train_scores4=np.empty([5, 10])\n",
    "train_scores4[:]=np.NaN\n",
    "test_scores4=np.empty([5, 10])\n",
    "test_scores4[:]=np.NaN\n",
    "fit_times4=np.empty([5, 10])\n",
    "fit_times4[:]=np.NaN\n",
    "score_times4=np.empty([5, 10])\n",
    "score_times4[:]=np.NaN\n",
    "cluster_times4=np.empty([5, 10])\n",
    "cluster_times4[:]=np.NaN\n",
    "\n",
    "train_sizes5=np.empty(5)\n",
    "train_sizes5[:]=np.NaN\n",
    "train_scores5=np.empty([5, 10])\n",
    "train_scores5[:]=np.NaN\n",
    "test_scores5=np.empty([5, 10])\n",
    "test_scores5[:]=np.NaN\n",
    "fit_times5=np.empty([5, 10])\n",
    "fit_times5[:]=np.NaN\n",
    "score_times5=np.empty([5, 10])\n",
    "score_times5[:]=np.NaN\n",
    "cluster_times5=np.empty([5, 10])\n",
    "cluster_times5[:]=np.NaN\n",
    "\n",
    "train_sizes6=np.empty(5)\n",
    "train_sizes6[:]=np.NaN\n",
    "train_scores6=np.empty([5, 10])\n",
    "train_scores6[:]=np.NaN\n",
    "test_scores6=np.empty([5, 10])\n",
    "test_scores6[:]=np.NaN\n",
    "fit_times6=np.empty([5, 10])\n",
    "fit_times6[:]=np.NaN\n",
    "score_times6=np.empty([5, 10])\n",
    "score_times6[:]=np.NaN\n",
    "cluster_times6=np.empty([5, 10])\n",
    "cluster_times6[:]=np.NaN\n",
    "\n",
    "train_sizes7=np.empty(5)\n",
    "train_sizes7[:]=np.NaN\n",
    "train_scores7=np.empty([5, 10])\n",
    "train_scores7[:]=np.NaN\n",
    "test_scores7=np.empty([5, 10])\n",
    "test_scores7[:]=np.NaN\n",
    "fit_times7=np.empty([5, 10])\n",
    "fit_times7[:]=np.NaN\n",
    "score_times7=np.empty([5, 10])\n",
    "score_times7[:]=np.NaN\n",
    "cluster_times7=np.empty([5, 10])\n",
    "cluster_times7[:]=np.NaN\n",
    "\n",
    "train_sizes8=np.empty(5)\n",
    "train_sizes8[:]=np.NaN\n",
    "train_scores8=np.empty([5, 10])\n",
    "train_scores8[:]=np.NaN\n",
    "test_scores8=np.empty([5, 10])\n",
    "test_scores8[:]=np.NaN\n",
    "fit_times8=np.empty([5, 10])\n",
    "fit_times8[:]=np.NaN\n",
    "score_times8=np.empty([5, 10])\n",
    "score_times8[:]=np.NaN\n",
    "cluster_times8=np.empty([5, 10])\n",
    "cluster_times8[:]=np.NaN\n",
    "\n",
    "train_sizes9=np.empty(5)\n",
    "train_sizes9[:]=np.NaN\n",
    "train_scores9=np.empty([5, 10])\n",
    "train_scores9[:]=np.NaN\n",
    "test_scores9=np.empty([5, 10])\n",
    "test_scores9[:]=np.NaN\n",
    "fit_times9=np.empty([5, 10])\n",
    "fit_times9[:]=np.NaN\n",
    "score_times9=np.empty([5, 10])\n",
    "score_times9[:]=np.NaN\n",
    "cluster_times9=np.empty([5, 10])\n",
    "cluster_times9[:]=np.NaN\n",
    "\n",
    "train_sizes10=np.empty(5)\n",
    "train_sizes10[:]=np.NaN\n",
    "train_scores10=np.empty([5, 5])\n",
    "train_scores10[:]=np.NaN\n",
    "test_scores10=np.empty([5, 5])\n",
    "test_scores10[:]=np.NaN\n",
    "fit_times10=np.empty([5, 5])\n",
    "fit_times10[:]=np.NaN\n",
    "score_times10=np.empty([5, 5])\n",
    "score_times10[:]=np.NaN\n",
    "cluster_times10=np.empty([5, 5])\n",
    "cluster_times10[:]=np.NaN\n",
    "\n",
    "train_sizes11=np.empty(5)\n",
    "train_sizes11[:]=np.NaN\n",
    "train_scores11=np.empty([5, 10])\n",
    "train_scores11[:]=np.NaN\n",
    "test_scores11=np.empty([5, 10])\n",
    "test_scores11[:]=np.NaN\n",
    "fit_times11=np.empty([5, 10])\n",
    "fit_times11[:]=np.NaN\n",
    "score_times11=np.empty([5, 10])\n",
    "score_times11[:]=np.NaN\n",
    "cluster_times11=np.empty([5, 10])\n",
    "cluster_times11[:]=np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_learning_curve=dict({1:train_sizes1,2:train_scores1,3:test_scores1,4:fit_times1,5:score_times1,6:cluster_times1})\n",
    "mlp_learning_curve=dict({1:train_sizes2,2:train_scores2,3:test_scores2,4:fit_times2,5:score_times2,6:cluster_times2})\n",
    "knn_learning_curve=dict({1:train_sizes3,2:train_scores3,3:test_scores3,4:fit_times3,5:score_times3,6:cluster_times3})\n",
    "logreg_learning_curve=dict({1:train_sizes4,2:train_scores4,3:test_scores4,4:fit_times4,5:score_times4,6:cluster_times4})\n",
    "linsvc_learning_curve=dict({1:train_sizes5,2:train_scores5,3:test_scores5,4:fit_times5,5:score_times5,6:cluster_times5})\n",
    "tree_learning_curve=dict({1:train_sizes6,2:train_scores6,3:test_scores6,4:fit_times6,5:score_times6,6:cluster_times6})\n",
    "forrest_learning_curve=dict({1:train_sizes7,2:train_scores7,3:test_scores7,4:fit_times7,5:score_times7,6:cluster_times7})\n",
    "adaboost_learning_curve=dict({1:train_sizes8,2:train_scores8,3:test_scores8,4:fit_times8,5:score_times8,6:cluster_times8})\n",
    "gnb_learning_curve=dict({1:train_sizes9,2:train_scores9,3:test_scores9,4:fit_times9,5:score_times9,6:cluster_times9})\n",
    "gpc_learning_curve=dict({1:train_sizes10,2:train_scores10,3:test_scores10,4:fit_times10,5:score_times10,6:cluster_times10})\n",
    "ridge_learning_curve=dict({1:train_sizes11,2:train_scores11,3:test_scores11,4:fit_times11,5:score_times11,6:cluster_times11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[\"accuracy\",\"macro_avg_precision\",\"macro_avg_recall\",\"macro_avg_f1_score\",\n",
    "       \"micro_avg_precision\",\"micro_avg_recall\",\"micro_avg_f1_score\",\n",
    "       \"weighted_avg_precision\",\"weighted_avg_recall\",\"weighted_avg_f1_score\",\n",
    "       \"fit_time\",\"cluster_time\"]\n",
    "\n",
    "df_svc = pd.DataFrame(index=names)\n",
    "df_mlp = pd.DataFrame(index=names)\n",
    "df_knn = pd.DataFrame(index=names)\n",
    "df_logreg = pd.DataFrame(index=names)\n",
    "df_linsvc = pd.DataFrame(index=names)\n",
    "df_tree = pd.DataFrame(index=names)\n",
    "df_forrest = pd.DataFrame(index=names)\n",
    "df_adaboost = pd.DataFrame(index=names)\n",
    "df_gnb = pd.DataFrame(index=names)\n",
    "df_gpc = pd.DataFrame(index=names)\n",
    "df_ridge = pd.DataFrame(index=names)\n",
    "\n",
    "\n",
    "faces = np.array(faces)\n",
    "labels=np.array(labels)\n",
    "\n",
    "des_list = []\n",
    "\n",
    "orb=cv2.ORB_create()\n",
    "#brisk = cv2.BRISK_create(30)\n",
    "#surf=cv2.xfeatures2d.SURF_create()\n",
    "#sift = cv2.xfeatures2d.SIFT_create(nOctaveLayers=3, contrastThreshold=0.03, edgeThreshold=10, sigma=1.6)\n",
    "\n",
    "list_to_delete=[] \n",
    "\n",
    "print(\"Finding descriptors for \",len(faces),\" images\")\n",
    "t0 = time()\n",
    "for i,face in enumerate(faces):\n",
    "    image_path=train_path\n",
    "    \n",
    "    kpts, des = orb.detectAndCompute(face, None)\n",
    "    #kpts, des = brisk.detectAndCompute(im, None)\n",
    "    #kpts, des = surf.detectAndCompute(im, None)\n",
    "    #kpts, des = sift.detectAndCompute(im, None)\n",
    "\n",
    "    if des is not None:\n",
    "        des_list.append((image_path, des))\n",
    "    else:\n",
    "        print(image_path)\n",
    "        list_to_delete.append(i)\n",
    "\n",
    "new_faces_ = [j for i, j in enumerate(faces) if i not in list_to_delete]\n",
    "faces=new_faces_\n",
    "\n",
    "new_labels_ = [j for i, j in enumerate(labels) if i not in list_to_delete]\n",
    "labels=new_labels_\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Found descriptors for \",len(des_list),\" images\")\n",
    "print(\"Found  \",len(labels),\" labels\")\n",
    "\n",
    "labels=np.array(labels)\n",
    "des_list=np.array(des_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf=StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in range(1,6):\n",
    "    print(\"--------------------------Start for size: \",size,\"----------------------------------------\")\n",
    "    for k_f,idx in enumerate(kf.split(X=des_list, y=labels)):\n",
    "        train_idx,test_idx=idx[0],idx[1]\n",
    "        x_train=des_list[train_idx]\n",
    "        y_train=labels[train_idx]\n",
    "\n",
    "        x_test=des_list[test_idx]\n",
    "        y_test=labels[test_idx]\n",
    "\n",
    "        print(\"Fold Number : \",k_f+1)\n",
    "\n",
    "        #Training==================================================================================================================================    \n",
    "        if (size==1):\n",
    "            X_train_new, X, y_train_new, y_ = train_test_split(x_train, y_train, train_size=0.22,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.22,shuffle=True,stratify=y_test)\n",
    "        elif (size==2):\n",
    "            X_train_new, X, y_train_new, y_ = train_test_split(x_train, y_train, train_size=0.325,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.325,shuffle=True,stratify=y_test)\n",
    "        elif (size==3):\n",
    "            X_train_new, X, y_train_new, y = train_test_split(x_train, y_train, train_size=0.55,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.55,shuffle=True,stratify=y_test)\n",
    "        elif (size==4):\n",
    "            X_train_new, X, y_train_new, y_ = train_test_split(x_train, y_train, train_size=0.77,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.77,shuffle=True,stratify=y_test)\n",
    "        else:\n",
    "            X_train_new=x_train\n",
    "            y_train_new=y_train\n",
    "            X_test_new=x_test\n",
    "            y_test_new=y_test\n",
    "        \n",
    "        svc_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        mlp_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        knn_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        logreg_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        linsvc_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        tree_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        forrest_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        adaboost_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        gnb_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        if (k_f<5):\n",
    "            gpc_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        ridge_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "\n",
    "        print(\"Stacking...\")\n",
    "        t0 = time()\n",
    "        descriptors = X_train_new[0][1]\n",
    "        for image_path, descriptor in X_train_new[1:]:\n",
    "            descriptors = np.vstack((descriptors, descriptor))\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "        descriptors_float = descriptors.astype(float) \n",
    "\n",
    "        print(\"Creating clusters and histogram...\")\n",
    "        t0 = time()\n",
    "        k = 200\n",
    "        voc, variance = kmeans(descriptors_float, k, 1)\n",
    "\n",
    "        im_features = np.zeros((len(X_train_new), k), \"float32\")\n",
    "        for i in range(len(X_train_new)):\n",
    "            words, distance = vq(X_train_new[i][1],voc)\n",
    "            for w in words:\n",
    "                im_features[i][w] += 1\n",
    "\n",
    "        nbr_occurences = np.sum( (im_features > 0) * 1, axis = 0)\n",
    "        idf = np.array(np.log((1.0*len(X_train_new)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "        stdSlr = StandardScaler().fit(im_features)\n",
    "        im_features = stdSlr.transform(im_features)\n",
    "        cluster_time=time() - t0\n",
    "        print(\"done in %0.3fs\" %cluster_time)\n",
    "        svc_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        mlp_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        knn_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        logreg_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        linsvc_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        tree_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        forrest_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        adaboost_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        gnb_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        if (k_f<5):\n",
    "            gpc_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        ridge_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "\n",
    "\n",
    "        #Here comes the fitting of the model\n",
    "        print(\"Training the svc model...\")############################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        svc=SVC(class_weight='balanced',C=68.05601024732132,gamma=19.032746691658865,kernel='linear',degree=3)    \n",
    "        svc.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        svc_fit_time=time() - t0\n",
    "        print(\"Training the svc done in %0.3fs\" %svc_fit_time)\n",
    "        svc_learning_curve[4][size-1][k_f]=svc_fit_time#setting fit_time\n",
    "        test_sc=svc.score(im_features, np.array(y_train_new))\n",
    "        svc_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "        print(\"Training the linsvc model...\")###################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        linsvc = LinearSVC(C=13.273988533706948,loss='hinge',class_weight=None,fit_intercept=True)    \n",
    "        linsvc.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        linsvc_fit_time=time() - t0\n",
    "        print(\"Training the linsvc done in %0.3fs\" %linsvc_fit_time)\n",
    "        linsvc_learning_curve[4][size-1][k_f]=linsvc_fit_time#setting fit_time\n",
    "        test_sc=linsvc.score(im_features, np.array(y_train_new))\n",
    "        linsvc_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the forrest model...\")#####################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        forrest = RandomForestClassifier(n_estimators = 290, random_state=30,max_depth=9,min_samples_leaf=2,class_weight='balanced',bootstrap=True)    \n",
    "        forrest.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        forrest_fit_time=time() - t0\n",
    "        print(\"Training the forrest done in %0.3fs\" %forrest_fit_time)\n",
    "        forrest_learning_curve[4][size-1][k_f]=forrest_fit_time#setting fit_time\n",
    "        test_sc=forrest.score(im_features, np.array(y_train_new))\n",
    "        forrest_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the logreg model...\")#######################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        logreg = LogisticRegression(class_weight=None,C=81.37904643771212,solver='newton-cg')\n",
    "        logreg.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        logreg_fit_time=time() - t0\n",
    "        print(\"Training the logreg done in %0.3fs\" %logreg_fit_time)\n",
    "        logreg_learning_curve[4][size-1][k_f]=logreg_fit_time#setting fit_time\n",
    "        test_sc=logreg.score(im_features, np.array(y_train_new))\n",
    "        logreg_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the tree model...\")#######################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        tree = DecisionTreeClassifier(random_state=0,criterion='entropy',min_impurity_decrease=0.009033508409721459,max_depth=None,min_samples_leaf=5,\n",
    "                                  max_leaf_nodes=7,max_features=None)    \n",
    "        tree.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        tree_fit_time=time() - t0\n",
    "        print(\"Training the tree done in %0.3fs\" %tree_fit_time)\n",
    "        tree_learning_curve[4][size-1][k_f]=tree_fit_time#setting fit_time\n",
    "        test_sc=tree.score(im_features, np.array(y_train_new))\n",
    "        tree_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the knn model...\")#########################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=10,p=2,leaf_size=41)    \n",
    "        knn.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        knn_fit_time=time() - t0\n",
    "        print(\"Training the knn done in %0.3fs\" %knn_fit_time)\n",
    "        knn_learning_curve[4][size-1][k_f]=knn_fit_time#setting fit_time\n",
    "        test_sc=knn.score(im_features, np.array(y_train_new))\n",
    "        knn_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the mlp model...\")###########################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        mlp = MLPClassifier(solver='adam',hidden_layer_sizes=(453,498,225,316),alpha=0.03009184217630222, verbose=0, early_stopping=True,activation='tanh',momentum=0.43299330454632257,learning_rate='constant')    \n",
    "        mlp.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        mlp_fit_time=time() - t0\n",
    "        print(\"Training the mlp done in %0.3fs\" %mlp_fit_time)\n",
    "        mlp_learning_curve[4][size-1][k_f]=mlp_fit_time#setting fit_time\n",
    "        test_sc=mlp.score(im_features, np.array(y_train_new))\n",
    "        mlp_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the adaboost model...\")########################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        adaboost = AdaBoostClassifier(random_state=0,n_estimators=248,learning_rate=0.10949478469869828)\n",
    "        adaboost.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        adaboost_fit_time=time() - t0\n",
    "        print(\"Training the adaboost done in %0.3fs\" %adaboost_fit_time)\n",
    "        adaboost_learning_curve[4][size-1][k_f]=adaboost_fit_time#setting fit_time\n",
    "        test_sc=adaboost.score(im_features, np.array(y_train_new))\n",
    "        adaboost_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the gnb model...\")###############################################################\n",
    "        t0 = time()\n",
    "\n",
    "        gnb = GaussianNB()    \n",
    "        gnb.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        gnb_fit_time=time() - t0\n",
    "        print(\"Training the gnb done in %0.3fs\" %gnb_fit_time)\n",
    "        gnb_learning_curve[4][size-1][k_f]=gnb_fit_time#setting fit_time\n",
    "        test_sc=gnb.score(im_features, np.array(y_train_new))\n",
    "        gnb_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        if (k_f<5): #GPC has less training because it takes a lot of time\n",
    "            print(\"Training the gpc model...\")##############################################################\n",
    "            t0 = time()\n",
    "\n",
    "            gpc = GaussianProcessClassifier(kernel=1.0*RBF(length_scale=2.331930318829218),random_state=0)    \n",
    "            gpc.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "            gpc_fit_time=time() - t0\n",
    "            print(\"Training the gpc done in %0.3fs\" %gpc_fit_time)\n",
    "            gpc_learning_curve[4][size-1][k_f]=gpc_fit_time#setting fit_time\n",
    "            test_sc=gpc.score(im_features, np.array(y_train_new))\n",
    "            gpc_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the ridge model...\")############################################################\n",
    "        t0 = time()\n",
    "\n",
    "        ridge = RidgeClassifier(alpha=0.5,solver='saga')    \n",
    "        ridge.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        ridge_fit_time=time() - t0\n",
    "        print(\"Training the ridge done in %0.3fs\" %ridge_fit_time)\n",
    "        ridge_learning_curve[4][size-1][k_f]=ridge_fit_time#setting fit_time\n",
    "        test_sc=ridge.score(im_features, np.array(y_train_new))\n",
    "        ridge_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "\n",
    "\n",
    "\n",
    "        #Testing=============================================================================================================================\n",
    "        print(\"Testing...\")     \n",
    "\n",
    "        print(\"Stacking...\")\n",
    "        t0 = time()\n",
    "        descriptors = X_test_new[0][1]\n",
    "        for image_path, descriptor in X_test_new[1:]:\n",
    "            descriptors = np.vstack((descriptors, descriptor))\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "        print(\"Calculating histogram, Scaling...\")\n",
    "        test_features = np.zeros((len(X_test_new), k), \"float32\")\n",
    "        for i in range(len(X_test_new)):\n",
    "            words, distance = vq(X_test_new[i][1],voc)\n",
    "            for w in words:\n",
    "                test_features[i][w] += 1\n",
    "\n",
    "        nbr_occurences = np.sum( (test_features > 0) * 1, axis = 0)\n",
    "        idf = np.array(np.log((1.0*len(X_test_new)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "        test_features = stdSlr.transform(test_features)\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "        if (size==5):\n",
    "        \n",
    "            true_class =  [training_names[i-1] for i in y_test_new]\n",
    "            print(\"Predicting Started\")\n",
    "            #svc========================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in svc.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            svc_learning_curve[5][size-1][k_f]=score_t#setting score_time            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            svc_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_svc[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       svc_fit_time,cluster_time]\n",
    "\n",
    "            #mlp====================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in mlp.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            mlp_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            mlp_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_mlp[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       mlp_fit_time,cluster_time]\n",
    "\n",
    "            #knn=================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in knn.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            knn_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            knn_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_knn[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       knn_fit_time,cluster_time]\n",
    "\n",
    "            #logreg==============================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in logreg.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            logreg_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            logreg_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_logreg[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       logreg_fit_time,cluster_time]\n",
    "\n",
    "            #linsvc===================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in linsvc.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            linsvc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            linsvc_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_linsvc[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       linsvc_fit_time,cluster_time]\n",
    "\n",
    "            #tree=================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in tree.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            tree_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            tree_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_tree[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       tree_fit_time,cluster_time]\n",
    "\n",
    "            #forrest======================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in forrest.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            forrest_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            forrest_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_forrest[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       forrest_fit_time,cluster_time]\n",
    "\n",
    "            #adaboost=======================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in adaboost.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            adaboost_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions, output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            adaboost_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_adaboost[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       adaboost_fit_time,cluster_time]\n",
    "\n",
    "            #gnb=================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in gnb.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            gnb_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            gnb_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_gnb[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       gnb_fit_time,cluster_time]\n",
    "\n",
    "            #gpc============================================================================================\n",
    "            if (k_f<5):\n",
    "                t0 = time()\n",
    "                predictions =  [training_names[i-1] for i in gpc.predict(test_features)]\n",
    "                score_t=time() - t0\n",
    "                gpc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "\n",
    "                report=classification_report(true_class, predictions,output_dict=True)\n",
    "                accuracy=report['accuracy']\n",
    "                gpc_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "                macro_avg_precision=report['macro avg']['precision']\n",
    "                macro_avg_recall=report['macro avg']['recall']\n",
    "                macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "                micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "                micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "                micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "                weighted_avg_precision=report['weighted avg']['precision']\n",
    "                weighted_avg_recall=report['weighted avg']['recall']\n",
    "                weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "                df_gpc[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                           micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                           weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                           gpc_fit_time,cluster_time]\n",
    "\n",
    "            #ridge==============================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in ridge.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            ridge_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            ridge_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_ridge[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       ridge_fit_time,cluster_time]\n",
    "\n",
    "        else:\n",
    "            #svc=============================\n",
    "            t0 = time()\n",
    "            test_scores=svc.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            svc_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            svc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #mlp==================================\n",
    "            t0 = time()\n",
    "            test_scores=mlp.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            mlp_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            mlp_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #knn=============================\n",
    "            t0 = time()\n",
    "            test_scores=knn.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            knn_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            knn_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "            #logreg====================================\n",
    "            t0 = time()\n",
    "            test_scores=logreg.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            logreg_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            logreg_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #linsvc=========================================\n",
    "            t0 = time()\n",
    "            test_scores=linsvc.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            linsvc_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            linsvc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #tree======================================\n",
    "            t0 = time()\n",
    "            test_scores=tree.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            tree_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            tree_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "            #forrest=========================================\n",
    "            t0 = time()\n",
    "            test_scores=forrest.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            forrest_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            forrest_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #adaboost==========================================\n",
    "            t0 = time()\n",
    "            test_scores=adaboost.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            adaboost_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            adaboost_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #gnb===========================================\n",
    "            t0 = time()\n",
    "            test_scores=gnb.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            gnb_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            gnb_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #gpc========================================\n",
    "            if (k_f<5):\n",
    "                t0 = time()\n",
    "                test_scores=gpc.score(test_features,y_test_new)\n",
    "                score_t=time() - t0\n",
    "                gpc_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "                gpc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #ridge=========================================\n",
    "            t0 = time()\n",
    "            test_scores=ridge.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            ridge_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            ridge_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "            \n",
    "        print(\"Predicting DONE for fold \",k_f+1)\n",
    "\n",
    "        \n",
    "    print(\"END OF LOOP for size: \",size)\n",
    "    \n",
    "print(\"End of ALL\")\n",
    "lfw['svc']=df_svc\n",
    "lfw['mlp']=df_mlp\n",
    "lfw['knn']=df_knn\n",
    "lfw['logreg']=df_logreg\n",
    "lfw['linsvc']=df_linsvc\n",
    "lfw['tree']=df_tree\n",
    "lfw['forrest']=df_forrest\n",
    "lfw['adaboost']=df_adaboost\n",
    "lfw['gnb']=df_gnb\n",
    "lfw['gpc']=df_gpc\n",
    "lfw['ridge']=df_ridge\n",
    "\n",
    "\n",
    "learning_curve_lfw['svc']=svc_learning_curve\n",
    "learning_curve_lfw['mlp']=mlp_learning_curve\n",
    "learning_curve_lfw['knn']=knn_learning_curve\n",
    "learning_curve_lfw['logreg']=logreg_learning_curve\n",
    "learning_curve_lfw['linsvc']=linsvc_learning_curve\n",
    "learning_curve_lfw['tree']=tree_learning_curve\n",
    "learning_curve_lfw['forrest']=forrest_learning_curve\n",
    "learning_curve_lfw['adaboost']=adaboost_learning_curve\n",
    "learning_curve_lfw['gnb']=gnb_learning_curve\n",
    "learning_curve_lfw['gpc']=gpc_learning_curve\n",
    "learning_curve_lfw['ridge']=ridge_learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('orb_extyale', 'wb')\n",
    "pickle.dump(orb_lfw, pickle_out)\n",
    "pickle_out.close()\n",
    "#pickle_in = open('my_dict.pickle', 'rb')\n",
    "#new_dict = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('orb_learning_curve_extyale.p', 'wb') as fp:\n",
    "        pickle.dump(orb_learning_curve_lfw, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BRISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_sizes1=np.empty(5)\n",
    "train_sizes1[:]=np.NaN\n",
    "train_scores1=np.empty([5, 10])\n",
    "train_scores1[:]=np.NaN\n",
    "test_scores1=np.empty([5, 10])\n",
    "test_scores1[:]=np.NaN\n",
    "fit_times1=np.empty([5, 10])\n",
    "fit_times1[:]=np.NaN\n",
    "score_times1=np.empty([5, 10])\n",
    "score_times1[:]=np.NaN\n",
    "cluster_times1=np.empty([5, 10])\n",
    "cluster_times1[:]=np.NaN\n",
    "\n",
    "train_sizes2=np.empty(5)\n",
    "train_sizes2[:]=np.NaN\n",
    "train_scores2=np.empty([5, 10])\n",
    "train_scores2[:]=np.NaN\n",
    "test_scores2=np.empty([5, 10])\n",
    "test_scores2[:]=np.NaN\n",
    "fit_times2=np.empty([5, 10])\n",
    "fit_times2[:]=np.NaN\n",
    "score_times2=np.empty([5, 10])\n",
    "score_times2[:]=np.NaN\n",
    "cluster_times2=np.empty([5, 10])\n",
    "cluster_times2[:]=np.NaN\n",
    "\n",
    "train_sizes3=np.empty(5)\n",
    "train_sizes3[:]=np.NaN\n",
    "train_scores3=np.empty([5, 10])\n",
    "train_scores3[:]=np.NaN\n",
    "test_scores3=np.empty([5, 10])\n",
    "test_scores3[:]=np.NaN\n",
    "fit_times3=np.empty([5, 10])\n",
    "fit_times3[:]=np.NaN\n",
    "score_times3=np.empty([5, 10])\n",
    "score_times3[:]=np.NaN\n",
    "cluster_times3=np.empty([5, 10])\n",
    "cluster_times3[:]=np.NaN\n",
    "\n",
    "train_sizes4=np.empty(5)\n",
    "train_sizes4[:]=np.NaN\n",
    "train_scores4=np.empty([5, 10])\n",
    "train_scores4[:]=np.NaN\n",
    "test_scores4=np.empty([5, 10])\n",
    "test_scores4[:]=np.NaN\n",
    "fit_times4=np.empty([5, 10])\n",
    "fit_times4[:]=np.NaN\n",
    "score_times4=np.empty([5, 10])\n",
    "score_times4[:]=np.NaN\n",
    "cluster_times4=np.empty([5, 10])\n",
    "cluster_times4[:]=np.NaN\n",
    "\n",
    "train_sizes5=np.empty(5)\n",
    "train_sizes5[:]=np.NaN\n",
    "train_scores5=np.empty([5, 10])\n",
    "train_scores5[:]=np.NaN\n",
    "test_scores5=np.empty([5, 10])\n",
    "test_scores5[:]=np.NaN\n",
    "fit_times5=np.empty([5, 10])\n",
    "fit_times5[:]=np.NaN\n",
    "score_times5=np.empty([5, 10])\n",
    "score_times5[:]=np.NaN\n",
    "cluster_times5=np.empty([5, 10])\n",
    "cluster_times5[:]=np.NaN\n",
    "\n",
    "train_sizes6=np.empty(5)\n",
    "train_sizes6[:]=np.NaN\n",
    "train_scores6=np.empty([5, 10])\n",
    "train_scores6[:]=np.NaN\n",
    "test_scores6=np.empty([5, 10])\n",
    "test_scores6[:]=np.NaN\n",
    "fit_times6=np.empty([5, 10])\n",
    "fit_times6[:]=np.NaN\n",
    "score_times6=np.empty([5, 10])\n",
    "score_times6[:]=np.NaN\n",
    "cluster_times6=np.empty([5, 10])\n",
    "cluster_times6[:]=np.NaN\n",
    "\n",
    "train_sizes7=np.empty(5)\n",
    "train_sizes7[:]=np.NaN\n",
    "train_scores7=np.empty([5, 10])\n",
    "train_scores7[:]=np.NaN\n",
    "test_scores7=np.empty([5, 10])\n",
    "test_scores7[:]=np.NaN\n",
    "fit_times7=np.empty([5, 10])\n",
    "fit_times7[:]=np.NaN\n",
    "score_times7=np.empty([5, 10])\n",
    "score_times7[:]=np.NaN\n",
    "cluster_times7=np.empty([5, 10])\n",
    "cluster_times7[:]=np.NaN\n",
    "\n",
    "train_sizes8=np.empty(5)\n",
    "train_sizes8[:]=np.NaN\n",
    "train_scores8=np.empty([5, 10])\n",
    "train_scores8[:]=np.NaN\n",
    "test_scores8=np.empty([5, 10])\n",
    "test_scores8[:]=np.NaN\n",
    "fit_times8=np.empty([5, 10])\n",
    "fit_times8[:]=np.NaN\n",
    "score_times8=np.empty([5, 10])\n",
    "score_times8[:]=np.NaN\n",
    "cluster_times8=np.empty([5, 10])\n",
    "cluster_times8[:]=np.NaN\n",
    "\n",
    "train_sizes9=np.empty(5)\n",
    "train_sizes9[:]=np.NaN\n",
    "train_scores9=np.empty([5, 10])\n",
    "train_scores9[:]=np.NaN\n",
    "test_scores9=np.empty([5, 10])\n",
    "test_scores9[:]=np.NaN\n",
    "fit_times9=np.empty([5, 10])\n",
    "fit_times9[:]=np.NaN\n",
    "score_times9=np.empty([5, 10])\n",
    "score_times9[:]=np.NaN\n",
    "cluster_times9=np.empty([5, 10])\n",
    "cluster_times9[:]=np.NaN\n",
    "\n",
    "train_sizes10=np.empty(5)\n",
    "train_sizes10[:]=np.NaN\n",
    "train_scores10=np.empty([5, 5])\n",
    "train_scores10[:]=np.NaN\n",
    "test_scores10=np.empty([5, 5])\n",
    "test_scores10[:]=np.NaN\n",
    "fit_times10=np.empty([5, 5])\n",
    "fit_times10[:]=np.NaN\n",
    "score_times10=np.empty([5, 5])\n",
    "score_times10[:]=np.NaN\n",
    "cluster_times10=np.empty([5, 5])\n",
    "cluster_times10[:]=np.NaN\n",
    "\n",
    "train_sizes11=np.empty(5)\n",
    "train_sizes11[:]=np.NaN\n",
    "train_scores11=np.empty([5, 10])\n",
    "train_scores11[:]=np.NaN\n",
    "test_scores11=np.empty([5, 10])\n",
    "test_scores11[:]=np.NaN\n",
    "fit_times11=np.empty([5, 10])\n",
    "fit_times11[:]=np.NaN\n",
    "score_times11=np.empty([5, 10])\n",
    "score_times11[:]=np.NaN\n",
    "cluster_times11=np.empty([5, 10])\n",
    "cluster_times11[:]=np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_learning_curve=dict({1:train_sizes1,2:train_scores1,3:test_scores1,4:fit_times1,5:score_times1,6:cluster_times1})\n",
    "mlp_learning_curve=dict({1:train_sizes2,2:train_scores2,3:test_scores2,4:fit_times2,5:score_times2,6:cluster_times2})\n",
    "knn_learning_curve=dict({1:train_sizes3,2:train_scores3,3:test_scores3,4:fit_times3,5:score_times3,6:cluster_times3})\n",
    "logreg_learning_curve=dict({1:train_sizes4,2:train_scores4,3:test_scores4,4:fit_times4,5:score_times4,6:cluster_times4})\n",
    "linsvc_learning_curve=dict({1:train_sizes5,2:train_scores5,3:test_scores5,4:fit_times5,5:score_times5,6:cluster_times5})\n",
    "tree_learning_curve=dict({1:train_sizes6,2:train_scores6,3:test_scores6,4:fit_times6,5:score_times6,6:cluster_times6})\n",
    "forrest_learning_curve=dict({1:train_sizes7,2:train_scores7,3:test_scores7,4:fit_times7,5:score_times7,6:cluster_times7})\n",
    "adaboost_learning_curve=dict({1:train_sizes8,2:train_scores8,3:test_scores8,4:fit_times8,5:score_times8,6:cluster_times8})\n",
    "gnb_learning_curve=dict({1:train_sizes9,2:train_scores9,3:test_scores9,4:fit_times9,5:score_times9,6:cluster_times9})\n",
    "gpc_learning_curve=dict({1:train_sizes10,2:train_scores10,3:test_scores10,4:fit_times10,5:score_times10,6:cluster_times10})\n",
    "ridge_learning_curve=dict({1:train_sizes11,2:train_scores11,3:test_scores11,4:fit_times11,5:score_times11,6:cluster_times11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[\"accuracy\",\"macro_avg_precision\",\"macro_avg_recall\",\"macro_avg_f1_score\",\n",
    "       \"micro_avg_precision\",\"micro_avg_recall\",\"micro_avg_f1_score\",\n",
    "       \"weighted_avg_precision\",\"weighted_avg_recall\",\"weighted_avg_f1_score\",\n",
    "       \"fit_time\",\"cluster_time\"]\n",
    "\n",
    "df_svc = pd.DataFrame(index=names)\n",
    "df_mlp = pd.DataFrame(index=names)\n",
    "df_knn = pd.DataFrame(index=names)\n",
    "df_logreg = pd.DataFrame(index=names)\n",
    "df_linsvc = pd.DataFrame(index=names)\n",
    "df_tree = pd.DataFrame(index=names)\n",
    "df_forrest = pd.DataFrame(index=names)\n",
    "df_adaboost = pd.DataFrame(index=names)\n",
    "df_gnb = pd.DataFrame(index=names)\n",
    "df_gpc = pd.DataFrame(index=names)\n",
    "df_ridge = pd.DataFrame(index=names)\n",
    "\n",
    "faces = np.array(faces)\n",
    "labels=np.array(labels)\n",
    "\n",
    "des_list = []\n",
    "\n",
    "#orb=cv2.ORB_create()\n",
    "brisk = cv2.BRISK_create(30)\n",
    "#surf=cv2.xfeatures2d.SURF_create()\n",
    "#sift = cv2.xfeatures2d.SIFT_create(nOctaveLayers=3, contrastThreshold=0.03, edgeThreshold=10, sigma=1.6)\n",
    "\n",
    "list_to_delete=[] \n",
    "\n",
    "print(\"Finding descriptors for \",len(faces),\" images\")\n",
    "t0 = time()\n",
    "for i,face in enumerate(faces):\n",
    "    image_path=train_path\n",
    "    \n",
    "    #kpts, des = orb.detectAndCompute(image_gray, None)\n",
    "    kpts, des = brisk.detectAndCompute(face, None)\n",
    "    #kpts, des = surf.detectAndCompute(im, None)\n",
    "    #kpts, des = sift.detectAndCompute(im, None)\n",
    "\n",
    "    if des is not None:\n",
    "        des_list.append((image_path, des))\n",
    "    else:\n",
    "        print(image_path)\n",
    "        list_to_delete.append(i)\n",
    "\n",
    "\n",
    "new_faces_ = [j for i, j in enumerate(faces) if i not in list_to_delete]\n",
    "faces=new_faces_\n",
    "\n",
    "new_labels_ = [j for i, j in enumerate(labels) if i not in list_to_delete]\n",
    "labels=new_labels_\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Found descriptors for \",len(des_list),\" images\")\n",
    "print(\"Found  \",len(labels),\" labels\")\n",
    "\n",
    "labels=np.array(labels)\n",
    "des_list=np.array(des_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for size in range(1,6):\n",
    "    print(\"--------------------------Start for size: \",size,\"----------------------------------------\")\n",
    "    for k_f,idx in enumerate(kf.split(X=des_list, y=labels)):\n",
    "        train_idx,test_idx=idx[0],idx[1]\n",
    "        x_train=des_list[train_idx]\n",
    "        y_train=labels[train_idx]\n",
    "\n",
    "        x_test=des_list[test_idx]\n",
    "        y_test=labels[test_idx]\n",
    "\n",
    "        print(\"Fold Number : \",k_f+1)\n",
    "\n",
    "        #Training==================================================================================================================================    \n",
    "        if (size==1):\n",
    "            X_train_new, X, y_train_new, y_ = train_test_split(x_train, y_train, train_size=0.22,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.22,shuffle=True,stratify=y_test)\n",
    "        elif (size==2):\n",
    "            X_train_new, X, y_train_new, y_ = train_test_split(x_train, y_train, train_size=0.325,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.325,shuffle=True,stratify=y_test)\n",
    "        elif (size==3):\n",
    "            X_train_new, X, y_train_new, y = train_test_split(x_train, y_train, train_size=0.55,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.55,shuffle=True,stratify=y_test)\n",
    "        elif (size==4):\n",
    "            X_train_new, X, y_train_new, y_ = train_test_split(x_train, y_train, train_size=0.77,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.77,shuffle=True,stratify=y_test)\n",
    "        else:\n",
    "            X_train_new=x_train\n",
    "            y_train_new=y_train\n",
    "            X_test_new=x_test\n",
    "            y_test_new=y_test\n",
    "        \n",
    "        svc_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        mlp_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        knn_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        logreg_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        linsvc_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        tree_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        forrest_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        adaboost_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        gnb_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        if (k_f<5):\n",
    "            gpc_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        ridge_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "\n",
    "        print(\"Stacking...\")\n",
    "        t0 = time()\n",
    "        descriptors = X_train_new[0][1]\n",
    "        for image_path, descriptor in X_train_new[1:]:\n",
    "            descriptors = np.vstack((descriptors, descriptor))\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "        descriptors_float = descriptors.astype(float) \n",
    "\n",
    "        print(\"Creating clusters and histogram...\")\n",
    "        t0 = time()\n",
    "        k = 200\n",
    "        voc, variance = kmeans(descriptors_float, k, 1)\n",
    "\n",
    "        im_features = np.zeros((len(X_train_new), k), \"float32\")\n",
    "        for i in range(len(X_train_new)):\n",
    "            words, distance = vq(X_train_new[i][1],voc)\n",
    "            for w in words:\n",
    "                im_features[i][w] += 1\n",
    "\n",
    "        nbr_occurences = np.sum( (im_features > 0) * 1, axis = 0)\n",
    "        idf = np.array(np.log((1.0*len(X_train_new)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "        stdSlr = StandardScaler().fit(im_features)\n",
    "        im_features = stdSlr.transform(im_features)\n",
    "        cluster_time=time() - t0\n",
    "        print(\"done in %0.3fs\" %cluster_time)\n",
    "        svc_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        mlp_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        knn_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        logreg_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        linsvc_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        tree_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        forrest_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        adaboost_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        gnb_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        if (k_f<5):\n",
    "            gpc_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        ridge_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "\n",
    "\n",
    "        #EDW MPAINEI TO MODELO GIA TO FITTING\n",
    "        print(\"Training the svc model...\")############################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        svc=SVC(class_weight='balanced',C=68.05601024732132,gamma=19.032746691658865,kernel='linear',degree=3)    \n",
    "        svc.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        svc_fit_time=time() - t0\n",
    "        print(\"Training the svc done in %0.3fs\" %svc_fit_time)\n",
    "        svc_learning_curve[4][size-1][k_f]=svc_fit_time#setting fit_time\n",
    "        test_sc=svc.score(im_features, np.array(y_train_new))\n",
    "        svc_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "        print(\"Training the linsvc model...\")###################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        linsvc = LinearSVC(C=13.273988533706948,loss='hinge',class_weight=None,fit_intercept=True)    \n",
    "        linsvc.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        linsvc_fit_time=time() - t0\n",
    "        print(\"Training the linsvc done in %0.3fs\" %linsvc_fit_time)\n",
    "        linsvc_learning_curve[4][size-1][k_f]=linsvc_fit_time#setting fit_time\n",
    "        test_sc=linsvc.score(im_features, np.array(y_train_new))\n",
    "        linsvc_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the forrest model...\")#####################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        forrest = RandomForestClassifier(n_estimators = 290, random_state=30,max_depth=9,min_samples_leaf=2,class_weight='balanced',bootstrap=True)    \n",
    "        forrest.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        forrest_fit_time=time() - t0\n",
    "        print(\"Training the forrest done in %0.3fs\" %forrest_fit_time)\n",
    "        forrest_learning_curve[4][size-1][k_f]=forrest_fit_time#setting fit_time\n",
    "        test_sc=forrest.score(im_features, np.array(y_train_new))\n",
    "        forrest_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the logreg model...\")#######################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        logreg = LogisticRegression(class_weight=None,C=81.37904643771212,solver='newton-cg')\n",
    "        logreg.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        logreg_fit_time=time() - t0\n",
    "        print(\"Training the logreg done in %0.3fs\" %logreg_fit_time)\n",
    "        logreg_learning_curve[4][size-1][k_f]=logreg_fit_time#setting fit_time\n",
    "        test_sc=logreg.score(im_features, np.array(y_train_new))\n",
    "        logreg_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the tree model...\")#######################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        tree = DecisionTreeClassifier(random_state=0,criterion='entropy',min_impurity_decrease=0.009033508409721459,max_depth=None,min_samples_leaf=5,\n",
    "                                  max_leaf_nodes=7,max_features=None)    \n",
    "        tree.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        tree_fit_time=time() - t0\n",
    "        print(\"Training the tree done in %0.3fs\" %tree_fit_time)\n",
    "        tree_learning_curve[4][size-1][k_f]=tree_fit_time#setting fit_time\n",
    "        test_sc=tree.score(im_features, np.array(y_train_new))\n",
    "        tree_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the knn model...\")#########################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=10,p=2,leaf_size=41)    \n",
    "        knn.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        knn_fit_time=time() - t0\n",
    "        print(\"Training the knn done in %0.3fs\" %knn_fit_time)\n",
    "        knn_learning_curve[4][size-1][k_f]=knn_fit_time#setting fit_time\n",
    "        test_sc=knn.score(im_features, np.array(y_train_new))\n",
    "        knn_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the mlp model...\")###########################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        mlp = MLPClassifier(solver='adam',hidden_layer_sizes=(453,498,225,316),alpha=0.03009184217630222, verbose=0, early_stopping=True,activation='tanh',momentum=0.43299330454632257,learning_rate='constant')    \n",
    "        mlp.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        mlp_fit_time=time() - t0\n",
    "        print(\"Training the mlp done in %0.3fs\" %mlp_fit_time)\n",
    "        mlp_learning_curve[4][size-1][k_f]=mlp_fit_time#setting fit_time\n",
    "        test_sc=mlp.score(im_features, np.array(y_train_new))\n",
    "        mlp_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the adaboost model...\")########################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        adaboost = AdaBoostClassifier(random_state=0,n_estimators=248,learning_rate=0.10949478469869828)\n",
    "        adaboost.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        adaboost_fit_time=time() - t0\n",
    "        print(\"Training the adaboost done in %0.3fs\" %adaboost_fit_time)\n",
    "        adaboost_learning_curve[4][size-1][k_f]=adaboost_fit_time#setting fit_time\n",
    "        test_sc=adaboost.score(im_features, np.array(y_train_new))\n",
    "        adaboost_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the gnb model...\")###############################################################\n",
    "        t0 = time()\n",
    "\n",
    "        gnb = GaussianNB()    \n",
    "        gnb.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        gnb_fit_time=time() - t0\n",
    "        print(\"Training the gnb done in %0.3fs\" %gnb_fit_time)\n",
    "        gnb_learning_curve[4][size-1][k_f]=gnb_fit_time#setting fit_time\n",
    "        test_sc=gnb.score(im_features, np.array(y_train_new))\n",
    "        gnb_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the gpc model...\")##############################################################\n",
    "        if (k_f<5):\n",
    "            t0 = time()\n",
    "\n",
    "            gpc = GaussianProcessClassifier(kernel=1.0*RBF(length_scale=2.331930318829218),random_state=0)    \n",
    "            gpc.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "            gpc_fit_time=time() - t0\n",
    "            print(\"Training the gpc done in %0.3fs\" %gpc_fit_time)\n",
    "            gpc_learning_curve[4][size-1][k_f]=gpc_fit_time#setting fit_time\n",
    "            test_sc=gpc.score(im_features, np.array(y_train_new))\n",
    "            gpc_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the ridge model...\")############################################################\n",
    "        t0 = time()\n",
    "\n",
    "        ridge = RidgeClassifier(alpha=0.5,solver='saga')    \n",
    "        ridge.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        ridge_fit_time=time() - t0\n",
    "        print(\"Training the ridge done in %0.3fs\" %ridge_fit_time)\n",
    "        ridge_learning_curve[4][size-1][k_f]=ridge_fit_time#setting fit_time\n",
    "        test_sc=ridge.score(im_features, np.array(y_train_new))\n",
    "        ridge_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "\n",
    "\n",
    "\n",
    "        #Testing=============================================================================================================================\n",
    "        print(\"Testing...\")     \n",
    "\n",
    "        print(\"Stacking...\")\n",
    "        t0 = time()\n",
    "        descriptors = X_test_new[0][1]\n",
    "        for image_path, descriptor in X_test_new[1:]:\n",
    "            descriptors = np.vstack((descriptors, descriptor))\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "        print(\"Calculating histogram, Scaling...\")\n",
    "        test_features = np.zeros((len(X_test_new), k), \"float32\")\n",
    "        for i in range(len(X_test_new)):\n",
    "            words, distance = vq(X_test_new[i][1],voc)\n",
    "            for w in words:\n",
    "                test_features[i][w] += 1\n",
    "\n",
    "        nbr_occurences = np.sum( (test_features > 0) * 1, axis = 0)\n",
    "        idf = np.array(np.log((1.0*len(X_test_new)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "        test_features = stdSlr.transform(test_features)\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "        if (size==5):\n",
    "        \n",
    "            true_class =  [training_names[i-1] for i in y_test_new]\n",
    "            print(\"Predicting Started\")\n",
    "            #svc========================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in svc.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            svc_learning_curve[5][size-1][k_f]=score_t#setting score_time            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            svc_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_svc[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       svc_fit_time,cluster_time]\n",
    "\n",
    "            #mlp====================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in mlp.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            mlp_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            mlp_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_mlp[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       mlp_fit_time,cluster_time]\n",
    "\n",
    "            #knn=================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in knn.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            knn_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            knn_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_knn[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       knn_fit_time,cluster_time]\n",
    "\n",
    "            #logreg==============================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in logreg.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            logreg_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            logreg_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_logreg[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       logreg_fit_time,cluster_time]\n",
    "\n",
    "            #linsvc===================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in linsvc.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            linsvc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            linsvc_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_linsvc[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       linsvc_fit_time,cluster_time]\n",
    "\n",
    "            #tree=================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in tree.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            tree_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            tree_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_tree[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       tree_fit_time,cluster_time]\n",
    "\n",
    "            #forrest======================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in forrest.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            forrest_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            forrest_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_forrest[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       forrest_fit_time,cluster_time]\n",
    "\n",
    "            #adaboost=======================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in adaboost.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            adaboost_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            adaboost_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_adaboost[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       adaboost_fit_time,cluster_time]\n",
    "\n",
    "            #gnb=================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in gnb.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            gnb_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            gnb_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_gnb[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       gnb_fit_time,cluster_time]\n",
    "\n",
    "            #gpc============================================================================================\n",
    "            if (k_f<5):\n",
    "                t0 = time()\n",
    "                predictions =  [training_names[i-1] for i in gpc.predict(test_features)]\n",
    "                score_t=time() - t0\n",
    "                gpc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "\n",
    "                report=classification_report(true_class, predictions,output_dict=True)\n",
    "                accuracy=report['accuracy']\n",
    "                gpc_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "                macro_avg_precision=report['macro avg']['precision']\n",
    "                macro_avg_recall=report['macro avg']['recall']\n",
    "                macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "                micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "                micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "                micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "                weighted_avg_precision=report['weighted avg']['precision']\n",
    "                weighted_avg_recall=report['weighted avg']['recall']\n",
    "                weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "                df_gpc[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                           micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                           weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                           gpc_fit_time,cluster_time]\n",
    "\n",
    "            #ridge==============================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in ridge.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            ridge_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            ridge_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_ridge[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       ridge_fit_time,cluster_time]\n",
    "\n",
    "        else:\n",
    "            #svc=============================\n",
    "            t0 = time()\n",
    "            test_scores=svc.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            svc_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            svc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #mlp==================================\n",
    "            t0 = time()\n",
    "            test_scores=mlp.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            mlp_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            mlp_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #knn=============================\n",
    "            t0 = time()\n",
    "            test_scores=knn.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            knn_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            knn_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "            #logreg====================================\n",
    "            t0 = time()\n",
    "            test_scores=logreg.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            logreg_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            logreg_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #linsvc=========================================\n",
    "            t0 = time()\n",
    "            test_scores=linsvc.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            linsvc_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            linsvc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #tree======================================\n",
    "            t0 = time()\n",
    "            test_scores=tree.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            tree_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            tree_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "            #forrest=========================================\n",
    "            t0 = time()\n",
    "            test_scores=forrest.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            forrest_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            forrest_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #adaboost==========================================\n",
    "            t0 = time()\n",
    "            test_scores=adaboost.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            adaboost_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            adaboost_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #gnb===========================================\n",
    "            t0 = time()\n",
    "            test_scores=gnb.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            gnb_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            gnb_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #gpc========================================\n",
    "            if (k_f<5):\n",
    "                t0 = time()\n",
    "                test_scores=gpc.score(test_features,y_test_new)\n",
    "                score_t=time() - t0\n",
    "                gpc_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "                gpc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #ridge=========================================\n",
    "            t0 = time()\n",
    "            test_scores=ridge.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            ridge_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            ridge_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "            \n",
    "        print(\"Predicting DONE for fold \",k_f+1)\n",
    "\n",
    "        \n",
    "    print(\"END OF LOOP for size: \",size)\n",
    "    \n",
    "print(\"End of ALL\")\n",
    "brisk['svc']=df_svc\n",
    "brisk['mlp']=df_mlp\n",
    "brisk['knn']=df_knn\n",
    "brisk['logreg']=df_logreg\n",
    "brisk['linsvc']=df_linsvc\n",
    "brisk['tree']=df_tree\n",
    "brisk['forrest']=df_forrest\n",
    "brisk['adaboost']=df_adaboost\n",
    "brisk['gnb']=df_gnb\n",
    "brisk['gpc']=df_gpc\n",
    "brisk['ridge']=df_ridge\n",
    "\n",
    "\n",
    "brisk_learning_curve['svc']=svc_learning_curve\n",
    "brisk_learning_curve['mlp']=mlp_learning_curve\n",
    "brisk_learning_curve['knn']=knn_learning_curve\n",
    "brisk_learning_curve['logreg']=logreg_learning_curve\n",
    "brisk_learning_curve['linsvc']=linsvc_learning_curve\n",
    "brisk_learning_curve['tree']=tree_learning_curve\n",
    "brisk_learning_curve['forrest']=forrest_learning_curve\n",
    "brisk_learning_curve['adaboost']=adaboost_learning_curve\n",
    "brisk_learning_curve['gnb']=gnb_learning_curve\n",
    "brisk_learning_curve['gpc']=gpc_learning_curve\n",
    "brisk_learning_curvec['ridge']=ridge_learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('brisk', 'wb')\n",
    "pickle.dump(brisk_lfw, pickle_out)\n",
    "pickle_out.close()\n",
    "#pickle_in = open('my_dict.pickle', 'rb')\n",
    "#new_dict = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('brisk_learning_curve.p', 'wb') as fp:\n",
    "    pickle.dump(brisk_learning_curve, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_sizes1=np.empty(5)\n",
    "train_sizes1[:]=np.NaN\n",
    "train_scores1=np.empty([5, 10])\n",
    "train_scores1[:]=np.NaN\n",
    "test_scores1=np.empty([5, 10])\n",
    "test_scores1[:]=np.NaN\n",
    "fit_times1=np.empty([5, 10])\n",
    "fit_times1[:]=np.NaN\n",
    "score_times1=np.empty([5, 10])\n",
    "score_times1[:]=np.NaN\n",
    "cluster_times1=np.empty([5, 10])\n",
    "cluster_times1[:]=np.NaN\n",
    "\n",
    "train_sizes2=np.empty(5)\n",
    "train_sizes2[:]=np.NaN\n",
    "train_scores2=np.empty([5, 10])\n",
    "train_scores2[:]=np.NaN\n",
    "test_scores2=np.empty([5, 10])\n",
    "test_scores2[:]=np.NaN\n",
    "fit_times2=np.empty([5, 10])\n",
    "fit_times2[:]=np.NaN\n",
    "score_times2=np.empty([5, 10])\n",
    "score_times2[:]=np.NaN\n",
    "cluster_times2=np.empty([5, 10])\n",
    "cluster_times2[:]=np.NaN\n",
    "\n",
    "train_sizes3=np.empty(5)\n",
    "train_sizes3[:]=np.NaN\n",
    "train_scores3=np.empty([5, 10])\n",
    "train_scores3[:]=np.NaN\n",
    "test_scores3=np.empty([5, 10])\n",
    "test_scores3[:]=np.NaN\n",
    "fit_times3=np.empty([5, 10])\n",
    "fit_times3[:]=np.NaN\n",
    "score_times3=np.empty([5, 10])\n",
    "score_times3[:]=np.NaN\n",
    "cluster_times3=np.empty([5, 10])\n",
    "cluster_times3[:]=np.NaN\n",
    "\n",
    "train_sizes4=np.empty(5)\n",
    "train_sizes4[:]=np.NaN\n",
    "train_scores4=np.empty([5, 10])\n",
    "train_scores4[:]=np.NaN\n",
    "test_scores4=np.empty([5, 10])\n",
    "test_scores4[:]=np.NaN\n",
    "fit_times4=np.empty([5, 10])\n",
    "fit_times4[:]=np.NaN\n",
    "score_times4=np.empty([5, 10])\n",
    "score_times4[:]=np.NaN\n",
    "cluster_times4=np.empty([5, 10])\n",
    "cluster_times4[:]=np.NaN\n",
    "\n",
    "train_sizes5=np.empty(5)\n",
    "train_sizes5[:]=np.NaN\n",
    "train_scores5=np.empty([5, 10])\n",
    "train_scores5[:]=np.NaN\n",
    "test_scores5=np.empty([5, 10])\n",
    "test_scores5[:]=np.NaN\n",
    "fit_times5=np.empty([5, 10])\n",
    "fit_times5[:]=np.NaN\n",
    "score_times5=np.empty([5, 10])\n",
    "score_times5[:]=np.NaN\n",
    "cluster_times5=np.empty([5, 10])\n",
    "cluster_times5[:]=np.NaN\n",
    "\n",
    "train_sizes6=np.empty(5)\n",
    "train_sizes6[:]=np.NaN\n",
    "train_scores6=np.empty([5, 10])\n",
    "train_scores6[:]=np.NaN\n",
    "test_scores6=np.empty([5, 10])\n",
    "test_scores6[:]=np.NaN\n",
    "fit_times6=np.empty([5, 10])\n",
    "fit_times6[:]=np.NaN\n",
    "score_times6=np.empty([5, 10])\n",
    "score_times6[:]=np.NaN\n",
    "cluster_times6=np.empty([5, 10])\n",
    "cluster_times6[:]=np.NaN\n",
    "\n",
    "train_sizes7=np.empty(5)\n",
    "train_sizes7[:]=np.NaN\n",
    "train_scores7=np.empty([5, 10])\n",
    "train_scores7[:]=np.NaN\n",
    "test_scores7=np.empty([5, 10])\n",
    "test_scores7[:]=np.NaN\n",
    "fit_times7=np.empty([5, 10])\n",
    "fit_times7[:]=np.NaN\n",
    "score_times7=np.empty([5, 10])\n",
    "score_times7[:]=np.NaN\n",
    "cluster_times7=np.empty([5, 10])\n",
    "cluster_times7[:]=np.NaN\n",
    "\n",
    "train_sizes8=np.empty(5)\n",
    "train_sizes8[:]=np.NaN\n",
    "train_scores8=np.empty([5, 10])\n",
    "train_scores8[:]=np.NaN\n",
    "test_scores8=np.empty([5, 10])\n",
    "test_scores8[:]=np.NaN\n",
    "fit_times8=np.empty([5, 10])\n",
    "fit_times8[:]=np.NaN\n",
    "score_times8=np.empty([5, 10])\n",
    "score_times8[:]=np.NaN\n",
    "cluster_times8=np.empty([5, 10])\n",
    "cluster_times8[:]=np.NaN\n",
    "\n",
    "train_sizes9=np.empty(5)\n",
    "train_sizes9[:]=np.NaN\n",
    "train_scores9=np.empty([5, 10])\n",
    "train_scores9[:]=np.NaN\n",
    "test_scores9=np.empty([5, 10])\n",
    "test_scores9[:]=np.NaN\n",
    "fit_times9=np.empty([5, 10])\n",
    "fit_times9[:]=np.NaN\n",
    "score_times9=np.empty([5, 10])\n",
    "score_times9[:]=np.NaN\n",
    "cluster_times9=np.empty([5, 10])\n",
    "cluster_times9[:]=np.NaN\n",
    "\n",
    "train_sizes10=np.empty(5)\n",
    "train_sizes10[:]=np.NaN\n",
    "train_scores10=np.empty([5, 5])\n",
    "train_scores10[:]=np.NaN\n",
    "test_scores10=np.empty([5, 5])\n",
    "test_scores10[:]=np.NaN\n",
    "fit_times10=np.empty([5, 5])\n",
    "fit_times10[:]=np.NaN\n",
    "score_times10=np.empty([5, 5])\n",
    "score_times10[:]=np.NaN\n",
    "cluster_times10=np.empty([5, 5])\n",
    "cluster_times10[:]=np.NaN\n",
    "\n",
    "train_sizes11=np.empty(5)\n",
    "train_sizes11[:]=np.NaN\n",
    "train_scores11=np.empty([5, 10])\n",
    "train_scores11[:]=np.NaN\n",
    "test_scores11=np.empty([5, 10])\n",
    "test_scores11[:]=np.NaN\n",
    "fit_times11=np.empty([5, 10])\n",
    "fit_times11[:]=np.NaN\n",
    "score_times11=np.empty([5, 10])\n",
    "score_times11[:]=np.NaN\n",
    "cluster_times11=np.empty([5, 10])\n",
    "cluster_times11[:]=np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_learning_curve=dict({1:train_sizes1,2:train_scores1,3:test_scores1,4:fit_times1,5:score_times1,6:cluster_times1})\n",
    "mlp_learning_curve=dict({1:train_sizes2,2:train_scores2,3:test_scores2,4:fit_times2,5:score_times2,6:cluster_times2})\n",
    "knn_learning_curve=dict({1:train_sizes3,2:train_scores3,3:test_scores3,4:fit_times3,5:score_times3,6:cluster_times3})\n",
    "logreg_learning_curve=dict({1:train_sizes4,2:train_scores4,3:test_scores4,4:fit_times4,5:score_times4,6:cluster_times4})\n",
    "linsvc_learning_curve=dict({1:train_sizes5,2:train_scores5,3:test_scores5,4:fit_times5,5:score_times5,6:cluster_times5})\n",
    "tree_learning_curve=dict({1:train_sizes6,2:train_scores6,3:test_scores6,4:fit_times6,5:score_times6,6:cluster_times6})\n",
    "forrest_learning_curve=dict({1:train_sizes7,2:train_scores7,3:test_scores7,4:fit_times7,5:score_times7,6:cluster_times7})\n",
    "adaboost_learning_curve=dict({1:train_sizes8,2:train_scores8,3:test_scores8,4:fit_times8,5:score_times8,6:cluster_times8})\n",
    "gnb_learning_curve=dict({1:train_sizes9,2:train_scores9,3:test_scores9,4:fit_times9,5:score_times9,6:cluster_times9})\n",
    "gpc_learning_curve=dict({1:train_sizes10,2:train_scores10,3:test_scores10,4:fit_times10,5:score_times10,6:cluster_times10})\n",
    "ridge_learning_curve=dict({1:train_sizes11,2:train_scores11,3:test_scores11,4:fit_times11,5:score_times11,6:cluster_times11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[\"accuracy\",\"macro_avg_precision\",\"macro_avg_recall\",\"macro_avg_f1_score\",\n",
    "       \"micro_avg_precision\",\"micro_avg_recall\",\"micro_avg_f1_score\",\n",
    "       \"weighted_avg_precision\",\"weighted_avg_recall\",\"weighted_avg_f1_score\",\n",
    "       \"fit_time\",\"cluster_time\"]\n",
    "\n",
    "df_svc = pd.DataFrame(index=names)\n",
    "df_mlp = pd.DataFrame(index=names)\n",
    "df_knn = pd.DataFrame(index=names)\n",
    "df_logreg = pd.DataFrame(index=names)\n",
    "df_linsvc = pd.DataFrame(index=names)\n",
    "df_tree = pd.DataFrame(index=names)\n",
    "df_forrest = pd.DataFrame(index=names)\n",
    "df_adaboost = pd.DataFrame(index=names)\n",
    "df_gnb = pd.DataFrame(index=names)\n",
    "df_gpc = pd.DataFrame(index=names)\n",
    "df_ridge = pd.DataFrame(index=names)\n",
    "\n",
    "faces = np.array(faces)\n",
    "labels=np.array(labels)\n",
    "\n",
    "des_list = []\n",
    "\n",
    "#orb=cv2.ORB_create()\n",
    "#brisk = cv2.BRISK_create(30)\n",
    "#surf=cv2.xfeatures2d.SURF_create()\n",
    "sift = cv2.xfeatures2d.SIFT_create(nOctaveLayers=3, contrastThreshold=0.03, edgeThreshold=10, sigma=1.6)\n",
    "\n",
    "list_to_delete=[] \n",
    "\n",
    "print(\"Finding descriptors for \",len(faces),\" images\")\n",
    "t0 = time()\n",
    "for i,face in enumerate(faces):\n",
    "    image_path=train_path\n",
    "    \n",
    "    #kpts, des = orb.detectAndCompute(image_gray, None)\n",
    "    #kpts, des = brisk.detectAndCompute(im, None)\n",
    "    #kpts, des = surf.detectAndCompute(im, None)\n",
    "    kpts, des = sift.detectAndCompute(face, None)\n",
    "\n",
    "    if des is not None:\n",
    "        des_list.append((image_path, des))\n",
    "    else:\n",
    "        print(image_path)\n",
    "        list_to_delete.append(i)\n",
    "\n",
    "\n",
    "new_faces_ = [j for i, j in enumerate(faces) if i not in list_to_delete]\n",
    "faces=new_faces_\n",
    "\n",
    "new_labels_ = [j for i, j in enumerate(labels) if i not in list_to_delete]\n",
    "labels=new_labels_\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Found descriptors for \",len(des_list),\" images\")\n",
    "print(\"Found  \",len(labels),\" labels\")\n",
    "\n",
    "labels=np.array(labels)\n",
    "des_list=np.array(des_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for size in range(1,6):\n",
    "    print(\"--------------------------Start for size: \",size,\"----------------------------------------\")\n",
    "    for k_f,idx in enumerate(kf.split(X=des_list, y=labels)):\n",
    "        train_idx,test_idx=idx[0],idx[1]\n",
    "        x_train=des_list[train_idx]\n",
    "        y_train=labels[train_idx]\n",
    "\n",
    "        x_test=des_list[test_idx]\n",
    "        y_test=labels[test_idx]\n",
    "\n",
    "        print(\"Fold Number : \",k_f+1)\n",
    "\n",
    "        #Training==================================================================================================================================    \n",
    "        if (size==1):\n",
    "            X_train_new, X, y_train_new, y_ = train_test_split(x_train, y_train, train_size=0.2,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.22,shuffle=True,stratify=y_test)\n",
    "        elif (size==2):\n",
    "            X_train_new, X, y_train_new, y_ = train_test_split(x_train, y_train, train_size=0.325,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.325,shuffle=True,stratify=y_test)\n",
    "        elif (size==3):\n",
    "            X_train_new, X, y_train_new, y = train_test_split(x_train, y_train, train_size=0.55,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.55,shuffle=True,stratify=y_test)\n",
    "        elif (size==4):\n",
    "            X_train_new, X, y_train_new, y_ = train_test_split(x_train, y_train, train_size=0.77,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.77,shuffle=True,stratify=y_test)\n",
    "        else:\n",
    "            X_train_new=x_train\n",
    "            y_train_new=y_train\n",
    "            X_test_new=x_test\n",
    "            y_test_new=y_test\n",
    "        \n",
    "        svc_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        mlp_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        knn_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        logreg_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        linsvc_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        tree_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        forrest_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        adaboost_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        gnb_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        if (k_f<5):\n",
    "            gpc_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        ridge_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "\n",
    "        print(\"Stacking...\")\n",
    "        t0 = time()\n",
    "        descriptors = X_train_new[0][1]\n",
    "        for image_path, descriptor in X_train_new[1:]:\n",
    "            descriptors = np.vstack((descriptors, descriptor))\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "        descriptors_float = descriptors.astype(float) \n",
    "\n",
    "        print(\"Creating clusters and histogram...\")\n",
    "        t0 = time()\n",
    "        k = 200\n",
    "        voc, variance = kmeans(descriptors_float, k, 1)\n",
    "\n",
    "        im_features = np.zeros((len(X_train_new), k), \"float32\")\n",
    "        for i in range(len(X_train_new)):\n",
    "            words, distance = vq(X_train_new[i][1],voc)\n",
    "            for w in words:\n",
    "                im_features[i][w] += 1\n",
    "\n",
    "        nbr_occurences = np.sum( (im_features > 0) * 1, axis = 0)\n",
    "        idf = np.array(np.log((1.0*len(X_train_new)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "        stdSlr = StandardScaler().fit(im_features)\n",
    "        im_features = stdSlr.transform(im_features)\n",
    "        cluster_time=time() - t0\n",
    "        print(\"done in %0.3fs\" %cluster_time)\n",
    "        svc_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        mlp_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        knn_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        logreg_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        linsvc_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        tree_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        forrest_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        adaboost_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        gnb_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        if (k_f<5):\n",
    "            gpc_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        ridge_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "\n",
    "\n",
    "        #EDW MPAINEI TO MODELO GIA TO FITTING\n",
    "        print(\"Training the svc model...\")############################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        svc=SVC(class_weight='balanced',C=68.05601024732132,gamma=19.032746691658865,kernel='linear',degree=3)    \n",
    "        svc.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        svc_fit_time=time() - t0\n",
    "        print(\"Training the svc done in %0.3fs\" %svc_fit_time)\n",
    "        svc_learning_curve[4][size-1][k_f]=svc_fit_time#setting fit_time\n",
    "        test_sc=svc.score(im_features, np.array(y_train_new))\n",
    "        svc_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "        print(\"Training the linsvc model...\")###################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        linsvc = LinearSVC(C=13.273988533706948,loss='hinge',class_weight=None,fit_intercept=True)    \n",
    "        linsvc.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        linsvc_fit_time=time() - t0\n",
    "        print(\"Training the linsvc done in %0.3fs\" %linsvc_fit_time)\n",
    "        linsvc_learning_curve[4][size-1][k_f]=linsvc_fit_time#setting fit_time\n",
    "        test_sc=linsvc.score(im_features, np.array(y_train_new))\n",
    "        linsvc_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the forrest model...\")#####################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        forrest = RandomForestClassifier(n_estimators = 290, random_state=30,max_depth=9,min_samples_leaf=2,class_weight='balanced',bootstrap=True)    \n",
    "        forrest.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        forrest_fit_time=time() - t0\n",
    "        print(\"Training the forrest done in %0.3fs\" %forrest_fit_time)\n",
    "        forrest_learning_curve[4][size-1][k_f]=forrest_fit_time#setting fit_time\n",
    "        test_sc=forrest.score(im_features, np.array(y_train_new))\n",
    "        forrest_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the logreg model...\")#######################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        logreg = LogisticRegression(class_weight=None,C=81.37904643771212,solver='newton-cg')\n",
    "        logreg.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        logreg_fit_time=time() - t0\n",
    "        print(\"Training the logreg done in %0.3fs\" %logreg_fit_time)\n",
    "        logreg_learning_curve[4][size-1][k_f]=logreg_fit_time#setting fit_time\n",
    "        test_sc=logreg.score(im_features, np.array(y_train_new))\n",
    "        logreg_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the tree model...\")#######################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        tree = DecisionTreeClassifier(random_state=0,criterion='entropy',min_impurity_decrease=0.009033508409721459,max_depth=None,min_samples_leaf=5,\n",
    "                                  max_leaf_nodes=7,max_features=None)    \n",
    "        tree.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        tree_fit_time=time() - t0\n",
    "        print(\"Training the tree done in %0.3fs\" %tree_fit_time)\n",
    "        tree_learning_curve[4][size-1][k_f]=tree_fit_time#setting fit_time\n",
    "        test_sc=tree.score(im_features, np.array(y_train_new))\n",
    "        tree_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the knn model...\")#########################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=10,p=2,leaf_size=41)    \n",
    "        knn.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        knn_fit_time=time() - t0\n",
    "        print(\"Training the knn done in %0.3fs\" %knn_fit_time)\n",
    "        knn_learning_curve[4][size-1][k_f]=knn_fit_time#setting fit_time\n",
    "        test_sc=knn.score(im_features, np.array(y_train_new))\n",
    "        knn_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the mlp model...\")###########################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        mlp = MLPClassifier(solver='adam',hidden_layer_sizes=(453,498,225,316),alpha=0.03009184217630222, verbose=0, early_stopping=True,activation='tanh',momentum=0.43299330454632257,learning_rate='constant')    \n",
    "        mlp.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        mlp_fit_time=time() - t0\n",
    "        print(\"Training the mlp done in %0.3fs\" %mlp_fit_time)\n",
    "        mlp_learning_curve[4][size-1][k_f]=mlp_fit_time#setting fit_time\n",
    "        test_sc=mlp.score(im_features, np.array(y_train_new))\n",
    "        mlp_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the adaboost model...\")########################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        adaboost = AdaBoostClassifier(random_state=0,n_estimators=248,learning_rate=0.10949478469869828)\n",
    "        adaboost.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        adaboost_fit_time=time() - t0\n",
    "        print(\"Training the adaboost done in %0.3fs\" %adaboost_fit_time)\n",
    "        adaboost_learning_curve[4][size-1][k_f]=adaboost_fit_time#setting fit_time\n",
    "        test_sc=adaboost.score(im_features, np.array(y_train_new))\n",
    "        adaboost_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the gnb model...\")###############################################################\n",
    "        t0 = time()\n",
    "\n",
    "        gnb = GaussianNB()    \n",
    "        gnb.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        gnb_fit_time=time() - t0\n",
    "        print(\"Training the gnb done in %0.3fs\" %gnb_fit_time)\n",
    "        gnb_learning_curve[4][size-1][k_f]=gnb_fit_time#setting fit_time\n",
    "        test_sc=gnb.score(im_features, np.array(y_train_new))\n",
    "        gnb_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the gpc model...\")##############################################################\n",
    "        if (k_f<5):\n",
    "            t0 = time()\n",
    "\n",
    "            gpc = GaussianProcessClassifier(kernel=1.0*RBF(length_scale=2.331930318829218),random_state=0)    \n",
    "            gpc.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "            gpc_fit_time=time() - t0\n",
    "            print(\"Training the gpc done in %0.3fs\" %gpc_fit_time)\n",
    "            gpc_learning_curve[4][size-1][k_f]=gpc_fit_time#setting fit_time\n",
    "            test_sc=gpc.score(im_features, np.array(y_train_new))\n",
    "            gpc_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the ridge model...\")############################################################\n",
    "        t0 = time()\n",
    "\n",
    "        ridge = RidgeClassifier(alpha=0.5,solver='saga')    \n",
    "        ridge.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        ridge_fit_time=time() - t0\n",
    "        print(\"Training the ridge done in %0.3fs\" %ridge_fit_time)\n",
    "        ridge_learning_curve[4][size-1][k_f]=ridge_fit_time#setting fit_time\n",
    "        test_sc=ridge.score(im_features, np.array(y_train_new))\n",
    "        ridge_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "\n",
    "\n",
    "\n",
    "        #Testing=============================================================================================================================\n",
    "        print(\"Testing...\")     \n",
    "\n",
    "        print(\"Stacking...\")\n",
    "        t0 = time()\n",
    "        descriptors = X_test_new[0][1]\n",
    "        for image_path, descriptor in X_test_new[1:]:\n",
    "            descriptors = np.vstack((descriptors, descriptor))\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "        print(\"Calculating histogram, Scaling...\")\n",
    "        test_features = np.zeros((len(X_test_new), k), \"float32\")\n",
    "        for i in range(len(X_test_new)):\n",
    "            words, distance = vq(X_test_new[i][1],voc)\n",
    "            for w in words:\n",
    "                test_features[i][w] += 1\n",
    "\n",
    "        nbr_occurences = np.sum( (test_features > 0) * 1, axis = 0)\n",
    "        idf = np.array(np.log((1.0*len(X_test_new)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "        test_features = stdSlr.transform(test_features)\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "        if (size==5):\n",
    "        \n",
    "            true_class =  [training_names[i-1] for i in y_test_new]\n",
    "            print(\"Predicting Started\")\n",
    "            #svc========================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in svc.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            svc_learning_curve[5][size-1][k_f]=score_t#setting score_time            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            svc_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_svc[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       svc_fit_time,cluster_time]\n",
    "\n",
    "            #mlp====================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in mlp.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            mlp_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            mlp_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_mlp[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       mlp_fit_time,cluster_time]\n",
    "\n",
    "            #knn=================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in knn.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            knn_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            knn_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_knn[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       knn_fit_time,cluster_time]\n",
    "\n",
    "            #logreg==============================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in logreg.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            logreg_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            logreg_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_logreg[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       logreg_fit_time,cluster_time]\n",
    "\n",
    "            #linsvc===================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in linsvc.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            linsvc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            linsvc_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_linsvc[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       linsvc_fit_time,cluster_time]\n",
    "\n",
    "            #tree=================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in tree.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            tree_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            tree_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_tree[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       tree_fit_time,cluster_time]\n",
    "\n",
    "            #forrest======================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in forrest.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            forrest_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            forrest_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_forrest[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       forrest_fit_time,cluster_time]\n",
    "\n",
    "            #adaboost=======================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in adaboost.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            adaboost_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            adaboost_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_adaboost[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       adaboost_fit_time,cluster_time]\n",
    "\n",
    "            #gnb=================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in gnb.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            gnb_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            gnb_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_gnb[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       gnb_fit_time,cluster_time]\n",
    "\n",
    "            #gpc============================================================================================\n",
    "            if (k_f<5):\n",
    "                t0 = time()\n",
    "                predictions =  [training_names[i-1] for i in gpc.predict(test_features)]\n",
    "                score_t=time() - t0\n",
    "                gpc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "\n",
    "                report=classification_report(true_class, predictions,output_dict=True)\n",
    "                accuracy=report['accuracy']\n",
    "                gpc_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "                macro_avg_precision=report['macro avg']['precision']\n",
    "                macro_avg_recall=report['macro avg']['recall']\n",
    "                macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "                micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "                micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "                micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "                weighted_avg_precision=report['weighted avg']['precision']\n",
    "                weighted_avg_recall=report['weighted avg']['recall']\n",
    "                weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "                df_gpc[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                           micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                           weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                           gpc_fit_time,cluster_time]\n",
    "\n",
    "            #ridge==============================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in ridge.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            ridge_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            ridge_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_ridge[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       ridge_fit_time,cluster_time]\n",
    "\n",
    "        else:\n",
    "            #svc=============================\n",
    "            t0 = time()\n",
    "            test_scores=svc.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            svc_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            svc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #mlp==================================\n",
    "            t0 = time()\n",
    "            test_scores=mlp.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            mlp_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            mlp_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #knn=============================\n",
    "            t0 = time()\n",
    "            test_scores=knn.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            knn_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            knn_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "            #logreg====================================\n",
    "            t0 = time()\n",
    "            test_scores=logreg.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            logreg_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            logreg_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #linsvc=========================================\n",
    "            t0 = time()\n",
    "            test_scores=linsvc.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            linsvc_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            linsvc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #tree======================================\n",
    "            t0 = time()\n",
    "            test_scores=tree.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            tree_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            tree_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "            #forrest=========================================\n",
    "            t0 = time()\n",
    "            test_scores=forrest.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            forrest_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            forrest_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #adaboost==========================================\n",
    "            t0 = time()\n",
    "            test_scores=adaboost.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            adaboost_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            adaboost_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #gnb===========================================\n",
    "            t0 = time()\n",
    "            test_scores=gnb.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            gnb_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            gnb_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #gpc========================================\n",
    "            if (k_f<5):\n",
    "                t0 = time()\n",
    "                test_scores=gpc.score(test_features,y_test_new)\n",
    "                score_t=time() - t0\n",
    "                gpc_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "                gpc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #ridge=========================================\n",
    "            t0 = time()\n",
    "            test_scores=ridge.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            ridge_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            ridge_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "            \n",
    "        print(\"Predicting DONE for fold \",k_f+1)\n",
    "\n",
    "        \n",
    "    print(\"END OF LOOP for size: \",size)\n",
    "    \n",
    "print(\"End of ALL\")\n",
    "sift['svc']=df_svc\n",
    "sift['mlp']=df_mlp\n",
    "sift['knn']=df_knn\n",
    "sift['logreg']=df_logreg\n",
    "sift['linsvc']=df_linsvc\n",
    "sift['tree']=df_tree\n",
    "sift['forrest']=df_forrest\n",
    "sift['adaboost']=df_adaboost\n",
    "sift['gnb']=df_gnb\n",
    "sift['gpc']=df_gpc\n",
    "sift['ridge']=df_ridge\n",
    "\n",
    "\n",
    "sift_learning_curve['svc']=svc_learning_curve\n",
    "sift_learning_curve['mlp']=mlp_learning_curve\n",
    "sift_learning_curve['knn']=knn_learning_curve\n",
    "sift_learning_curve['logreg']=logreg_learning_curve\n",
    "sift_learning_curve['linsvc']=linsvc_learning_curve\n",
    "sift_learning_curve['tree']=tree_learning_curve\n",
    "sift_learning_curve['forrest']=forrest_learning_curve\n",
    "sift_learning_curve['adaboost']=adaboost_learning_curve\n",
    "sift_learning_curve['gnb']=gnb_learning_curve\n",
    "sift_learning_curve['gpc']=gpc_learning_curve\n",
    "sift_learning_curve['ridge']=ridge_learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('sift_extyale', 'wb')\n",
    "pickle.dump(sift_lfw, pickle_out)\n",
    "pickle_out.close()\n",
    "#pickle_in = open('my_dict.pickle', 'rb')\n",
    "#new_dict = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sift_learning_curve.p', 'wb') as fp:\n",
    "    pickle.dump(sift_learning_curve, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SURF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_sizes1=np.empty(5)\n",
    "train_sizes1[:]=np.NaN\n",
    "train_scores1=np.empty([5, 10])\n",
    "train_scores1[:]=np.NaN\n",
    "test_scores1=np.empty([5, 10])\n",
    "test_scores1[:]=np.NaN\n",
    "fit_times1=np.empty([5, 10])\n",
    "fit_times1[:]=np.NaN\n",
    "score_times1=np.empty([5, 10])\n",
    "score_times1[:]=np.NaN\n",
    "cluster_times1=np.empty([5, 10])\n",
    "cluster_times1[:]=np.NaN\n",
    "\n",
    "train_sizes2=np.empty(5)\n",
    "train_sizes2[:]=np.NaN\n",
    "train_scores2=np.empty([5, 10])\n",
    "train_scores2[:]=np.NaN\n",
    "test_scores2=np.empty([5, 10])\n",
    "test_scores2[:]=np.NaN\n",
    "fit_times2=np.empty([5, 10])\n",
    "fit_times2[:]=np.NaN\n",
    "score_times2=np.empty([5, 10])\n",
    "score_times2[:]=np.NaN\n",
    "cluster_times2=np.empty([5, 10])\n",
    "cluster_times2[:]=np.NaN\n",
    "\n",
    "train_sizes3=np.empty(5)\n",
    "train_sizes3[:]=np.NaN\n",
    "train_scores3=np.empty([5, 10])\n",
    "train_scores3[:]=np.NaN\n",
    "test_scores3=np.empty([5, 10])\n",
    "test_scores3[:]=np.NaN\n",
    "fit_times3=np.empty([5, 10])\n",
    "fit_times3[:]=np.NaN\n",
    "score_times3=np.empty([5, 10])\n",
    "score_times3[:]=np.NaN\n",
    "cluster_times3=np.empty([5, 10])\n",
    "cluster_times3[:]=np.NaN\n",
    "\n",
    "train_sizes4=np.empty(5)\n",
    "train_sizes4[:]=np.NaN\n",
    "train_scores4=np.empty([5, 10])\n",
    "train_scores4[:]=np.NaN\n",
    "test_scores4=np.empty([5, 10])\n",
    "test_scores4[:]=np.NaN\n",
    "fit_times4=np.empty([5, 10])\n",
    "fit_times4[:]=np.NaN\n",
    "score_times4=np.empty([5, 10])\n",
    "score_times4[:]=np.NaN\n",
    "cluster_times4=np.empty([5, 10])\n",
    "cluster_times4[:]=np.NaN\n",
    "\n",
    "train_sizes5=np.empty(5)\n",
    "train_sizes5[:]=np.NaN\n",
    "train_scores5=np.empty([5, 10])\n",
    "train_scores5[:]=np.NaN\n",
    "test_scores5=np.empty([5, 10])\n",
    "test_scores5[:]=np.NaN\n",
    "fit_times5=np.empty([5, 10])\n",
    "fit_times5[:]=np.NaN\n",
    "score_times5=np.empty([5, 10])\n",
    "score_times5[:]=np.NaN\n",
    "cluster_times5=np.empty([5, 10])\n",
    "cluster_times5[:]=np.NaN\n",
    "\n",
    "train_sizes6=np.empty(5)\n",
    "train_sizes6[:]=np.NaN\n",
    "train_scores6=np.empty([5, 10])\n",
    "train_scores6[:]=np.NaN\n",
    "test_scores6=np.empty([5, 10])\n",
    "test_scores6[:]=np.NaN\n",
    "fit_times6=np.empty([5, 10])\n",
    "fit_times6[:]=np.NaN\n",
    "score_times6=np.empty([5, 10])\n",
    "score_times6[:]=np.NaN\n",
    "cluster_times6=np.empty([5, 10])\n",
    "cluster_times6[:]=np.NaN\n",
    "\n",
    "train_sizes7=np.empty(5)\n",
    "train_sizes7[:]=np.NaN\n",
    "train_scores7=np.empty([5, 10])\n",
    "train_scores7[:]=np.NaN\n",
    "test_scores7=np.empty([5, 10])\n",
    "test_scores7[:]=np.NaN\n",
    "fit_times7=np.empty([5, 10])\n",
    "fit_times7[:]=np.NaN\n",
    "score_times7=np.empty([5, 10])\n",
    "score_times7[:]=np.NaN\n",
    "cluster_times7=np.empty([5, 10])\n",
    "cluster_times7[:]=np.NaN\n",
    "\n",
    "train_sizes8=np.empty(5)\n",
    "train_sizes8[:]=np.NaN\n",
    "train_scores8=np.empty([5, 10])\n",
    "train_scores8[:]=np.NaN\n",
    "test_scores8=np.empty([5, 10])\n",
    "test_scores8[:]=np.NaN\n",
    "fit_times8=np.empty([5, 10])\n",
    "fit_times8[:]=np.NaN\n",
    "score_times8=np.empty([5, 10])\n",
    "score_times8[:]=np.NaN\n",
    "cluster_times8=np.empty([5, 10])\n",
    "cluster_times8[:]=np.NaN\n",
    "\n",
    "train_sizes9=np.empty(5)\n",
    "train_sizes9[:]=np.NaN\n",
    "train_scores9=np.empty([5, 10])\n",
    "train_scores9[:]=np.NaN\n",
    "test_scores9=np.empty([5, 10])\n",
    "test_scores9[:]=np.NaN\n",
    "fit_times9=np.empty([5, 10])\n",
    "fit_times9[:]=np.NaN\n",
    "score_times9=np.empty([5, 10])\n",
    "score_times9[:]=np.NaN\n",
    "cluster_times9=np.empty([5, 10])\n",
    "cluster_times9[:]=np.NaN\n",
    "\n",
    "train_sizes10=np.empty(5)\n",
    "train_sizes10[:]=np.NaN\n",
    "train_scores10=np.empty([5, 5])\n",
    "train_scores10[:]=np.NaN\n",
    "test_scores10=np.empty([5, 5])\n",
    "test_scores10[:]=np.NaN\n",
    "fit_times10=np.empty([5, 5])\n",
    "fit_times10[:]=np.NaN\n",
    "score_times10=np.empty([5, 5])\n",
    "score_times10[:]=np.NaN\n",
    "cluster_times10=np.empty([5, 5])\n",
    "cluster_times10[:]=np.NaN\n",
    "\n",
    "train_sizes11=np.empty(5)\n",
    "train_sizes11[:]=np.NaN\n",
    "train_scores11=np.empty([5, 10])\n",
    "train_scores11[:]=np.NaN\n",
    "test_scores11=np.empty([5, 10])\n",
    "test_scores11[:]=np.NaN\n",
    "fit_times11=np.empty([5, 10])\n",
    "fit_times11[:]=np.NaN\n",
    "score_times11=np.empty([5, 10])\n",
    "score_times11[:]=np.NaN\n",
    "cluster_times11=np.empty([5, 10])\n",
    "cluster_times11[:]=np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_learning_curve=dict({1:train_sizes1,2:train_scores1,3:test_scores1,4:fit_times1,5:score_times1,6:cluster_times1})\n",
    "mlp_learning_curve=dict({1:train_sizes2,2:train_scores2,3:test_scores2,4:fit_times2,5:score_times2,6:cluster_times2})\n",
    "knn_learning_curve=dict({1:train_sizes3,2:train_scores3,3:test_scores3,4:fit_times3,5:score_times3,6:cluster_times3})\n",
    "logreg_learning_curve=dict({1:train_sizes4,2:train_scores4,3:test_scores4,4:fit_times4,5:score_times4,6:cluster_times4})\n",
    "linsvc_learning_curve=dict({1:train_sizes5,2:train_scores5,3:test_scores5,4:fit_times5,5:score_times5,6:cluster_times5})\n",
    "tree_learning_curve=dict({1:train_sizes6,2:train_scores6,3:test_scores6,4:fit_times6,5:score_times6,6:cluster_times6})\n",
    "forrest_learning_curve=dict({1:train_sizes7,2:train_scores7,3:test_scores7,4:fit_times7,5:score_times7,6:cluster_times7})\n",
    "adaboost_learning_curve=dict({1:train_sizes8,2:train_scores8,3:test_scores8,4:fit_times8,5:score_times8,6:cluster_times8})\n",
    "gnb_learning_curve=dict({1:train_sizes9,2:train_scores9,3:test_scores9,4:fit_times9,5:score_times9,6:cluster_times9})\n",
    "gpc_learning_curve=dict({1:train_sizes10,2:train_scores10,3:test_scores10,4:fit_times10,5:score_times10,6:cluster_times10})\n",
    "ridge_learning_curve=dict({1:train_sizes11,2:train_scores11,3:test_scores11,4:fit_times11,5:score_times11,6:cluster_times11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[\"accuracy\",\"macro_avg_precision\",\"macro_avg_recall\",\"macro_avg_f1_score\",\n",
    "       \"micro_avg_precision\",\"micro_avg_recall\",\"micro_avg_f1_score\",\n",
    "       \"weighted_avg_precision\",\"weighted_avg_recall\",\"weighted_avg_f1_score\",\n",
    "       \"fit_time\",\"cluster_time\"]\n",
    "\n",
    "df_svc = pd.DataFrame(index=names)\n",
    "df_mlp = pd.DataFrame(index=names)\n",
    "df_knn = pd.DataFrame(index=names)\n",
    "df_logreg = pd.DataFrame(index=names)\n",
    "df_linsvc = pd.DataFrame(index=names)\n",
    "df_tree = pd.DataFrame(index=names)\n",
    "df_forrest = pd.DataFrame(index=names)\n",
    "df_adaboost = pd.DataFrame(index=names)\n",
    "df_gnb = pd.DataFrame(index=names)\n",
    "df_gpc = pd.DataFrame(index=names)\n",
    "df_ridge = pd.DataFrame(index=names)\n",
    "\n",
    "faces = np.array(faces)\n",
    "labels=np.array(labels)\n",
    "\n",
    "des_list = []\n",
    "\n",
    "#orb=cv2.ORB_create()\n",
    "#brisk = cv2.BRISK_create(30)\n",
    "surf=cv2.xfeatures2d.SURF_create()\n",
    "#sift = cv2.xfeatures2d.SIFT_create(nOctaveLayers=3, contrastThreshold=0.03, edgeThreshold=10, sigma=1.6)\n",
    "\n",
    "list_to_delete=[] \n",
    "\n",
    "print(\"Finding descriptors for \",len(faces),\" images\")\n",
    "t0 = time()\n",
    "for i,face in enumerate(faces):\n",
    "    image_path=train_path\n",
    "        \n",
    "    #kpts, des = orb.detectAndCompute(image_gray, None)\n",
    "    #kpts, des = brisk.detectAndCompute(im, None)\n",
    "    kpts, des = surf.detectAndCompute(face, None)\n",
    "    #kpts, des = sift.detectAndCompute(im, None)\n",
    "\n",
    "    if des is not None:\n",
    "        des_list.append((image_path, des))\n",
    "    else:\n",
    "        print(image_path)\n",
    "        list_to_delete.append(i)\n",
    "\n",
    "\n",
    "new_faces_ = [j for i, j in enumerate(faces) if i not in list_to_delete]\n",
    "faces=new_faces_\n",
    "\n",
    "new_labels_ = [j for i, j in enumerate(labels) if i not in list_to_delete]\n",
    "labels=new_labels_\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Found descriptors for \",len(des_list),\" images\")\n",
    "print(\"Found  \",len(labels),\" labels\")\n",
    "\n",
    "labels=np.array(labels)\n",
    "des_list=np.array(des_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for size in range(1,6):\n",
    "    print(\"--------------------------Start for size: \",size,\"----------------------------------------\")\n",
    "    for k_f,idx in enumerate(kf.split(X=des_list, y=labels)):\n",
    "        train_idx,test_idx=idx[0],idx[1]\n",
    "        x_train=des_list[train_idx]\n",
    "        y_train=labels[train_idx]\n",
    "\n",
    "        x_test=des_list[test_idx]\n",
    "        y_test=labels[test_idx]\n",
    "\n",
    "        print(\"Fold Number : \",k_f+1)\n",
    "\n",
    "        #Training==================================================================================================================================    \n",
    "        if (size==1):\n",
    "            X_train_new, X, y_train_new, y_ = train_test_split(x_train, y_train, train_size=0.22,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.22,shuffle=True,stratify=y_test)\n",
    "        elif (size==2):\n",
    "            X_train_new, X, y_train_new, y_ = train_test_split(x_train, y_train, train_size=0.325,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.325,shuffle=True,stratify=y_test)\n",
    "        elif (size==3):\n",
    "            X_train_new, X, y_train_new, y = train_test_split(x_train, y_train, train_size=0.55,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.55,shuffle=True,stratify=y_test)\n",
    "        elif (size==4):\n",
    "            X_train_new, X, y_train_new, y_ = train_test_split(x_train, y_train, train_size=0.77,shuffle=True,stratify=y_train)\n",
    "            X_, X_test_new, y_, y_test_new = train_test_split(x_test, y_test, test_size=0.77,shuffle=True,stratify=y_test)\n",
    "        else:\n",
    "            X_train_new=x_train\n",
    "            y_train_new=y_train\n",
    "            X_test_new=x_test\n",
    "            y_test_new=y_test\n",
    "        \n",
    "        svc_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        mlp_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        knn_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        logreg_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        linsvc_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        tree_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        forrest_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        adaboost_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        gnb_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        if (k_f<5):\n",
    "            gpc_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "        ridge_learning_curve[1][size-1]=len(X_train_new)#setting train_size\n",
    "\n",
    "        print(\"Stacking...\")\n",
    "        t0 = time()\n",
    "        descriptors = X_train_new[0][1]\n",
    "        for image_path, descriptor in X_train_new[1:]:\n",
    "            descriptors = np.vstack((descriptors, descriptor))\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "        descriptors_float = descriptors.astype(float) \n",
    "\n",
    "        print(\"Creating clusters and histogram...\")\n",
    "        t0 = time()\n",
    "        k = 200\n",
    "        voc, variance = kmeans(descriptors_float, k, 1)\n",
    "\n",
    "        im_features = np.zeros((len(X_train_new), k), \"float32\")\n",
    "        for i in range(len(X_train_new)):\n",
    "            words, distance = vq(X_train_new[i][1],voc)\n",
    "            for w in words:\n",
    "                im_features[i][w] += 1\n",
    "\n",
    "        nbr_occurences = np.sum( (im_features > 0) * 1, axis = 0)\n",
    "        idf = np.array(np.log((1.0*len(X_train_new)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "        stdSlr = StandardScaler().fit(im_features)\n",
    "        im_features = stdSlr.transform(im_features)\n",
    "        cluster_time=time() - t0\n",
    "        print(\"done in %0.3fs\" %cluster_time)\n",
    "        svc_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        mlp_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        knn_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        logreg_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        linsvc_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        tree_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        forrest_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        adaboost_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        gnb_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        if (k_f<5):\n",
    "            gpc_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "        ridge_learning_curve[6][size-1][k_f]=cluster_time#setting cluster_time\n",
    "\n",
    "\n",
    "        #EDW MPAINEI TO MODELO GIA TO FITTING\n",
    "        print(\"Training the svc model...\")############################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        svc=SVC(class_weight='balanced',C=68.05601024732132,gamma=19.032746691658865,kernel='linear',degree=3)    \n",
    "        svc.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        svc_fit_time=time() - t0\n",
    "        print(\"Training the svc done in %0.3fs\" %svc_fit_time)\n",
    "        svc_learning_curve[4][size-1][k_f]=svc_fit_time#setting fit_time\n",
    "        test_sc=svc.score(im_features, np.array(y_train_new))\n",
    "        svc_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "        print(\"Training the linsvc model...\")###################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        linsvc = LinearSVC(C=13.273988533706948,loss='hinge',class_weight=None,fit_intercept=True)    \n",
    "        linsvc.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        linsvc_fit_time=time() - t0\n",
    "        print(\"Training the linsvc done in %0.3fs\" %linsvc_fit_time)\n",
    "        linsvc_learning_curve[4][size-1][k_f]=linsvc_fit_time#setting fit_time\n",
    "        test_sc=linsvc.score(im_features, np.array(y_train_new))\n",
    "        linsvc_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the forrest model...\")#####################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        forrest = RandomForestClassifier(n_estimators = 290, random_state=30,max_depth=9,min_samples_leaf=2,class_weight='balanced',bootstrap=True)    \n",
    "        forrest.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        forrest_fit_time=time() - t0\n",
    "        print(\"Training the forrest done in %0.3fs\" %forrest_fit_time)\n",
    "        forrest_learning_curve[4][size-1][k_f]=forrest_fit_time#setting fit_time\n",
    "        test_sc=forrest.score(im_features, np.array(y_train_new))\n",
    "        forrest_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the logreg model...\")#######################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        logreg = LogisticRegression(class_weight=None,C=81.37904643771212,solver='newton-cg')\n",
    "        logreg.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        logreg_fit_time=time() - t0\n",
    "        print(\"Training the logreg done in %0.3fs\" %logreg_fit_time)\n",
    "        logreg_learning_curve[4][size-1][k_f]=logreg_fit_time#setting fit_time\n",
    "        test_sc=logreg.score(im_features, np.array(y_train_new))\n",
    "        logreg_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the tree model...\")#######################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        tree = DecisionTreeClassifier(random_state=0,criterion='entropy',min_impurity_decrease=0.009033508409721459,max_depth=None,min_samples_leaf=5,\n",
    "                                  max_leaf_nodes=7,max_features=None)    \n",
    "        tree.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        tree_fit_time=time() - t0\n",
    "        print(\"Training the tree done in %0.3fs\" %tree_fit_time)\n",
    "        tree_learning_curve[4][size-1][k_f]=tree_fit_time#setting fit_time\n",
    "        test_sc=tree.score(im_features, np.array(y_train_new))\n",
    "        tree_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the knn model...\")#########################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=10,p=2,leaf_size=41)    \n",
    "        knn.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        knn_fit_time=time() - t0\n",
    "        print(\"Training the knn done in %0.3fs\" %knn_fit_time)\n",
    "        knn_learning_curve[4][size-1][k_f]=knn_fit_time#setting fit_time\n",
    "        test_sc=knn.score(im_features, np.array(y_train_new))\n",
    "        knn_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the mlp model...\")###########################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        mlp = MLPClassifier(solver='adam',hidden_layer_sizes=(453,498,225,316),alpha=0.03009184217630222, verbose=0, early_stopping=True,activation='tanh',momentum=0.43299330454632257,learning_rate='constant')    \n",
    "        mlp.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        mlp_fit_time=time() - t0\n",
    "        print(\"Training the mlp done in %0.3fs\" %mlp_fit_time)\n",
    "        mlp_learning_curve[4][size-1][k_f]=mlp_fit_time#setting fit_time\n",
    "        test_sc=mlp.score(im_features, np.array(y_train_new))\n",
    "        mlp_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the adaboost model...\")########################################################################\n",
    "        t0 = time()\n",
    "\n",
    "        adaboost = AdaBoostClassifier(random_state=0,n_estimators=248,learning_rate=0.10949478469869828)\n",
    "        adaboost.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        adaboost_fit_time=time() - t0\n",
    "        print(\"Training the adaboost done in %0.3fs\" %adaboost_fit_time)\n",
    "        adaboost_learning_curve[4][size-1][k_f]=adaboost_fit_time#setting fit_time\n",
    "        test_sc=adaboost.score(im_features, np.array(y_train_new))\n",
    "        adaboost_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the gnb model...\")###############################################################\n",
    "        t0 = time()\n",
    "\n",
    "        gnb = GaussianNB()    \n",
    "        gnb.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        gnb_fit_time=time() - t0\n",
    "        print(\"Training the gnb done in %0.3fs\" %gnb_fit_time)\n",
    "        gnb_learning_curve[4][size-1][k_f]=gnb_fit_time#setting fit_time\n",
    "        test_sc=gnb.score(im_features, np.array(y_train_new))\n",
    "        gnb_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the gpc model...\")##############################################################\n",
    "        if (k_f<5):\n",
    "            t0 = time()\n",
    "\n",
    "            gpc = GaussianProcessClassifier(kernel=1.0*RBF(length_scale=2.331930318829218),random_state=0)    \n",
    "            gpc.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "            gpc_fit_time=time() - t0\n",
    "            print(\"Training the gpc done in %0.3fs\" %gpc_fit_time)\n",
    "            gpc_learning_curve[4][size-1][k_f]=gpc_fit_time#setting fit_time\n",
    "            test_sc=gpc.score(im_features, np.array(y_train_new))\n",
    "            gpc_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "        \n",
    "\n",
    "        print(\"Training the ridge model...\")############################################################\n",
    "        t0 = time()\n",
    "\n",
    "        ridge = RidgeClassifier(alpha=0.5,solver='saga')    \n",
    "        ridge.fit(im_features, np.array(y_train_new))\n",
    "\n",
    "        ridge_fit_time=time() - t0\n",
    "        print(\"Training the ridge done in %0.3fs\" %ridge_fit_time)\n",
    "        ridge_learning_curve[4][size-1][k_f]=ridge_fit_time#setting fit_time\n",
    "        test_sc=ridge.score(im_features, np.array(y_train_new))\n",
    "        ridge_learning_curve[2][size-1][k_f]=test_sc#setting train_score\n",
    "\n",
    "\n",
    "\n",
    "        #Testing=============================================================================================================================\n",
    "        print(\"Testing...\")     \n",
    "\n",
    "        print(\"Stacking...\")\n",
    "        t0 = time()\n",
    "        descriptors = X_test_new[0][1]\n",
    "        for image_path, descriptor in X_test_new[1:]:\n",
    "            descriptors = np.vstack((descriptors, descriptor))\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "        print(\"Calculating histogram, Scaling...\")\n",
    "        test_features = np.zeros((len(X_test_new), k), \"float32\")\n",
    "        for i in range(len(X_test_new)):\n",
    "            words, distance = vq(X_test_new[i][1],voc)\n",
    "            for w in words:\n",
    "                test_features[i][w] += 1\n",
    "\n",
    "        nbr_occurences = np.sum( (test_features > 0) * 1, axis = 0)\n",
    "        idf = np.array(np.log((1.0*len(X_test_new)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "        test_features = stdSlr.transform(test_features)\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "        if (size==5):\n",
    "        \n",
    "            true_class =  [training_names[i-1] for i in y_test_new]\n",
    "            print(\"Predicting Started\")\n",
    "            #svc========================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in svc.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            svc_learning_curve[5][size-1][k_f]=score_t#setting score_time            \n",
    "\n",
    "            report=classification_report(true_class, predictions, output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            svc_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_svc[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       svc_fit_time,cluster_time]\n",
    "\n",
    "            #mlp====================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in mlp.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            mlp_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            mlp_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_mlp[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       mlp_fit_time,cluster_time]\n",
    "\n",
    "            #knn=================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in knn.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            knn_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            knn_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_knn[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       knn_fit_time,cluster_time]\n",
    "\n",
    "            #logreg==============================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in logreg.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            logreg_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            logreg_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_logreg[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       logreg_fit_time,cluster_time]\n",
    "\n",
    "            #linsvc===================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in linsvc.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            linsvc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            linsvc_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_linsvc[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       linsvc_fit_time,cluster_time]\n",
    "\n",
    "            #tree=================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in tree.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            tree_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            tree_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_tree[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       tree_fit_time,cluster_time]\n",
    "\n",
    "            #forrest======================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in forrest.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            forrest_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            forrest_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_forrest[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       forrest_fit_time,cluster_time]\n",
    "\n",
    "            #adaboost=======================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in adaboost.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            adaboost_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            adaboost_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_adaboost[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       adaboost_fit_time,cluster_time]\n",
    "\n",
    "            #gnb=================================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in gnb.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            gnb_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            gnb_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_gnb[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       gnb_fit_time,cluster_time]\n",
    "\n",
    "            #gpc============================================================================================\n",
    "            if (k_f<5):\n",
    "                t0 = time()\n",
    "                predictions =  [training_names[i-1] for i in gpc.predict(test_features)]\n",
    "                score_t=time() - t0\n",
    "                gpc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "\n",
    "                report=classification_report(true_class, predictions,output_dict=True)\n",
    "                accuracy=report['accuracy']\n",
    "                gpc_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "                macro_avg_precision=report['macro avg']['precision']\n",
    "                macro_avg_recall=report['macro avg']['recall']\n",
    "                macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "                micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "                micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "                micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "                weighted_avg_precision=report['weighted avg']['precision']\n",
    "                weighted_avg_recall=report['weighted avg']['recall']\n",
    "                weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "                df_gpc[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                           micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                           weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                           gpc_fit_time,cluster_time]\n",
    "\n",
    "            #ridge==============================================================================================\n",
    "            t0 = time()\n",
    "            predictions =  [training_names[i-1] for i in ridge.predict(test_features)]\n",
    "            score_t=time() - t0\n",
    "            ridge_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "\n",
    "            report=classification_report(true_class, predictions,output_dict=True)\n",
    "            accuracy=report['accuracy']\n",
    "            ridge_learning_curve[3][size-1][k_f]=accuracy#setting test_scores\n",
    "            macro_avg_precision=report['macro avg']['precision']\n",
    "            macro_avg_recall=report['macro avg']['recall']\n",
    "            macro_avg_f1_score=report['macro avg']['f1-score']\n",
    "            micro_avg_precision=precision_score(true_class, predictions, average='micro')\n",
    "            micro_avg_recall=recall_score(true_class, predictions, average='micro')\n",
    "            micro_avg_f1_score=f1_score(true_class, predictions, average='micro')\n",
    "            weighted_avg_precision=report['weighted avg']['precision']\n",
    "            weighted_avg_recall=report['weighted avg']['recall']\n",
    "            weighted_avg_f1_score=report['weighted avg']['f1-score']\n",
    "\n",
    "            df_ridge[k_f+1]=[accuracy,macro_avg_precision,macro_avg_recall,macro_avg_f1_score,\n",
    "                       micro_avg_precision,micro_avg_recall,micro_avg_f1_score,\n",
    "                       weighted_avg_precision,weighted_avg_recall,weighted_avg_f1_score,\n",
    "                       ridge_fit_time,cluster_time]\n",
    "\n",
    "        else:\n",
    "            #svc=============================\n",
    "            t0 = time()\n",
    "            test_scores=svc.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            svc_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            svc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #mlp==================================\n",
    "            t0 = time()\n",
    "            test_scores=mlp.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            mlp_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            mlp_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #knn=============================\n",
    "            t0 = time()\n",
    "            test_scores=knn.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            knn_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            knn_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "            #logreg====================================\n",
    "            t0 = time()\n",
    "            test_scores=logreg.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            logreg_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            logreg_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #linsvc=========================================\n",
    "            t0 = time()\n",
    "            test_scores=linsvc.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            linsvc_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            linsvc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #tree======================================\n",
    "            t0 = time()\n",
    "            test_scores=tree.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            tree_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            tree_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "            #forrest=========================================\n",
    "            t0 = time()\n",
    "            test_scores=forrest.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            forrest_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            forrest_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #adaboost==========================================\n",
    "            t0 = time()\n",
    "            test_scores=adaboost.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            adaboost_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            adaboost_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #gnb===========================================\n",
    "            t0 = time()\n",
    "            test_scores=gnb.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            gnb_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            gnb_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #gpc========================================\n",
    "            if (k_f<5):\n",
    "                t0 = time()\n",
    "                test_scores=gpc.score(test_features,y_test_new)\n",
    "                score_t=time() - t0\n",
    "                gpc_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "                gpc_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "\n",
    "            #ridge=========================================\n",
    "            t0 = time()\n",
    "            test_scores=ridge.score(test_features,y_test_new)\n",
    "            score_t=time() - t0\n",
    "            ridge_learning_curve[3][size-1][k_f]=test_scores#setting test_scores\n",
    "            ridge_learning_curve[5][size-1][k_f]=score_t#setting score_time\n",
    "            \n",
    "            \n",
    "        print(\"Predicting DONE for fold \",k_f+1)\n",
    "\n",
    "        \n",
    "    print(\"END OF LOOP for size: \",size)\n",
    "    \n",
    "print(\"End of ALL\")\n",
    "surf['svc']=df_svc\n",
    "surf['mlp']=df_mlp\n",
    "surf['knn']=df_knn\n",
    "surf['logreg']=df_logreg\n",
    "surf['linsvc']=df_linsvc\n",
    "surf['tree']=df_tree\n",
    "surf['forrest']=df_forrest\n",
    "surf['adaboost']=df_adaboost\n",
    "surf['gnb']=df_gnb\n",
    "surf['gpc']=df_gpc\n",
    "surf['ridge']=df_ridge\n",
    "\n",
    "\n",
    "surf_learning_curve['svc']=svc_learning_curve\n",
    "surf_learning_curve['mlp']=mlp_learning_curve\n",
    "surf_learning_curve['knn']=knn_learning_curve\n",
    "surf_learning_curve['logreg']=logreg_learning_curve\n",
    "surf_learning_curve['linsvc']=linsvc_learning_curve\n",
    "surf_learning_curve['tree']=tree_learning_curve\n",
    "surf_learning_curve['forrest']=forrest_learning_curve\n",
    "surf_learning_curve['adaboost']=adaboost_learning_curve\n",
    "surf_learning_curve['gnb']=gnb_learning_curve\n",
    "surf_learning_curve['gpc']=gpc_learning_curve\n",
    "surf_learning_curve['ridge']=ridge_learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('surf_extyale', 'wb')\n",
    "pickle.dump(surf, pickle_out)\n",
    "pickle_out.close()\n",
    "#pickle_in = open('my_dict.pickle', 'rb')\n",
    "#new_dict = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('surf_learning_curve.p', 'wb') as fp:\n",
    "    pickle.dump(surf_learning_curve, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
