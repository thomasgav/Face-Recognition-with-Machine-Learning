{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:  # Python 3.x\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face and eyes detection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(image):\n",
    "    #image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haar_classifier = cv2.CascadeClassifier('C:/Users/Thomas/Documents/face_detection/haarcascades/haarcascade_frontalface_default.xml')\n",
    "    face = haar_classifier.detectMultiScale(image,minNeighbors=6,minSize=(75, 75)) #oi parametroi allazoun analoga to dataset\n",
    "    if (len(face)==1): #if 1 face is found\n",
    "        (x,y,w,h) = face[0]\n",
    "        return True, image[y:y+w, x:x+h], face[0]\n",
    "    elif (len(face)==0): #if no faces are detected\n",
    "        \n",
    "        return False, \"zero\"\n",
    "    else: #if more than 1 faces are detected, the biggest is kept (the smaller ones usually belong in the background)\n",
    "        biggest=0\n",
    "        pos=0\n",
    "        for i,(x,y,w,h) in enumerate(face):\n",
    "            if biggest<(h*w):\n",
    "                biggest=h*w\n",
    "                pos=i\n",
    "        return True, image[y:y+w, x:x+h], face[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(image):\n",
    "    #image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haar_classifier = cv2.CascadeClassifier('C:/Users/Thomas/Documents/face_detection/haarcascades/haarcascade_frontalface_default.xml')\n",
    "    face = haar_classifier.detectMultiScale(image)#,scaleFactor=1.2, minNeighbors=5)\n",
    "    if (len(face)==1): #if 1 face is found\n",
    "        (x,y,w,h) = face[0]\n",
    "        '''\n",
    "        for (x,y,w,h) in face: \n",
    "            cv2.rectangle(image, (x,y), (x+w,y+h), (255,255,255), 3)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        '''\n",
    "        return True, image[y:y+w, x:x+h], face[0]\n",
    "    elif (len(face)==0): #if no faces are detected\n",
    "        return False, \"zero\"\n",
    "    else: #if more than 1 faces are detected\n",
    "        return False, \"more\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_detection(image):\n",
    "    #image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haar_classifier = cv2.CascadeClassifier('C:/Users/Thomas/Documents/face_detection/haarcascades/haarcascade_eye.xml')\n",
    "    eyes = haar_classifier.detectMultiScale(image, minNeighbors=4, minSize=(30, 30))\n",
    "    if (len(eyes)==2): #if 2 eyes are detected\n",
    "        return True, eyes\n",
    "    else:\n",
    "        haar_classifier = cv2.CascadeClassifier('C:/Users/Thomas/Documents/face_detection/haarcascades/haarcascade_eye_tree_eyeglasses.xml')\n",
    "        glasses = haar_classifier.detectMultiScale(image)\n",
    "        if (len(glasses)==2):\n",
    "            return True, glasses\n",
    "        else:\n",
    "            return False, \"more or less\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_pr_curve=[]\n",
    "fisher_pr_curve=[]\n",
    "sift_pr_curve=[]\n",
    "surf_pr_curve=[]\n",
    "orb_pr_curve=[]\n",
    "brisk_pr_curve=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath=('C:/Users/Thomas/Documents/Datasets/lfw(250x250)/')\n",
    "min_faces=30\n",
    "faces=[]\n",
    "labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=[] #all the names are saved here\n",
    "total_photos_seen=0 \n",
    "n_classes=0\n",
    "folders = os.listdir(datapath)\n",
    "for folder in folders:\n",
    "    label = os.path.basename(folder)\n",
    "    training_images_path = datapath + '/' + folder\n",
    "    num_of_faces = len(os.listdir(training_images_path))\n",
    "    #if num_of_faces>=min_faces:   #people with low number of faces are skipped\n",
    "    target_names.append(label)\n",
    "    n_classes=n_classes+1\n",
    "    faces_per_person=0\n",
    "    for image in os.listdir(training_images_path):\n",
    "        total_photos_seen=total_photos_seen+1\n",
    "        image_path = training_images_path + '/' + image\n",
    "        training_image = cv2.imread(image_path)\n",
    "        #face=cv2.cvtColor(training_image,cv2.COLOR_BGR2GRAY)\n",
    "        #resized=cv2.resize(face,(224,224),interpolation=cv2.INTER_AREA)\n",
    "        result_im=face_detection(training_image) #this function returns TRUE/FALSE, the cut image and the coordinates of where the cut was made\n",
    "        if result_im[0]: #if TRUE (face detected) then the cut face goes into the array\n",
    "            cut_face=result_im[1]\n",
    "            faces.append(cut_face)\n",
    "            labels.append(n_classes)\n",
    "\n",
    "        '''\n",
    "        if faces_per_person==45:\n",
    "                break\n",
    "        ''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_faces=[]\n",
    "new_labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_faces=0\n",
    "#unwanted_images=[3,110,113,166,238,245,349,398,444,903,978,1194,1218] \n",
    "for i in range(len(faces)):\n",
    "    #if i not in unwanted_images: in case there are pictures that cannot be processed\n",
    "    training_image = cv2.imread(faces[i])\n",
    "    result_im=eye_detection(training_image) #finding the place of the eyes\n",
    "    \n",
    "    if result_im[0]: #process of finding the angle of the two eyes, and alighnment\n",
    "        rotated_faces=rotated_faces+1\n",
    "        (x1,y1,w1,h1)=result_im[1][0]\n",
    "        (x2,y2,w2,h2)=result_im[1][1]\n",
    "        eye1_center_x=x1+(w1/2)\n",
    "        eye1_center_y=y1+(h1/2)\n",
    "        eye2_center_x=x2+(w2/2)\n",
    "        eye2_center_y=y2+(h2/2)\n",
    "        if (eye1_center_x>eye2_center_y):\n",
    "            deltaY = eye1_center_y - eye2_center_y \n",
    "            deltaX = eye1_center_x - eye2_center_x\n",
    "        else:\n",
    "            deltaY = eye2_center_y - eye1_center_y \n",
    "            deltaX = eye2_center_x - eye1_center_x\n",
    "        my_radians = math.atan2(deltaY , deltaX)\n",
    "        my_degrees = math.degrees(my_radians)\n",
    "\n",
    "        #rotation\n",
    "        rows, cols = training_image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((cols/2, rows/2), my_degrees, 1)\n",
    "        img_rotated = cv2.warpAffine(training_image, M, (cols,rows))\n",
    "        '''\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        plt.text(0,0,i)\n",
    "        plt.imshow(img_rotated)\n",
    "        plt.show()\n",
    "        '''\n",
    "\n",
    "        #scaling (all images will become 200x200)\n",
    "        #if before the conversion the image is smaller than 200x200 INTER_LINEAR will be used, else INTER_AREA will be used\n",
    "        image_size=rows*cols        \n",
    "        if (image_size<=40000):\n",
    "            scaled_image=cv2.resize(img_rotated, (200, 200), interpolation=cv2.INTER_LINEAR)\n",
    "        else:\n",
    "            scaled_image=cv2.resize(img_rotated, (200, 200), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        #normalization\n",
    "        norm_img = np.zeros((200, 200))\n",
    "        norm_img = cv2.normalize(scaled_image, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "        final_image = cv2.cvtColor(norm_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        new_faces.append(final_image)\n",
    "        new_labels.append(labels[i])\n",
    "        \n",
    "faces=new_faces\n",
    "labels=new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_faces = []\n",
    "\n",
    "for face in faces:\n",
    "    flat_faces.append(face.reshape(-1))        \n",
    "flat_faces = np.array(flat_faces)\n",
    "labels=np.array(labels)     \n",
    "\n",
    "Y = label_binarize(labels, classes=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(flat_faces,Y,test_size=0.30,stratify=Y,shuffle=True,random_state = 42)\n",
    "\n",
    "pca = PCA(n_components=142, svd_solver='randomized',whiten=True)\n",
    "\n",
    "\n",
    "clf=SVC(class_weight='balanced',C=28.104130383007977,gamma=7.281641758356972,kernel='poly',degree=1)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                ('clf', clf)])\n",
    "classifier1 = OneVsRestClassifier(pipe)\n",
    "classifier1.fit(X_train, y_train)\n",
    "y_score_svc = classifier1.decision_function(X_test)\n",
    "eigen_pr_curve.append((\"svc\",y_test,y_score_svc))\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3,p=2,leaf_size=50)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                ('knn', knn)])\n",
    "classifier2 = OneVsRestClassifier(pipe)\n",
    "classifier2.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_knn = classifier2.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_knn = classifier2.predict_proba(X_test)\n",
    "eigen_pr_curve.append((\"knn\",y_test,y_score_knn))\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(solver='adam',hidden_layer_sizes=(333,200,496,347,495),alpha=0.08193742846113258,\n",
    "                    learning_rate='invscaling', activation='tanh',momentum=0.5725450935194276,verbose=False, early_stopping=True)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                ('mlp', mlp)])\n",
    "classifier3 = OneVsRestClassifier(pipe)\n",
    "classifier3.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_mlp = classifier3.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_mlp = classifier3.predict_proba(X_test)\n",
    "eigen_pr_curve.append((\"mlp\",y_test,y_score_mlp))\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(class_weight='balanced',C=33.60545334855496,solver='sag')\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                ('logreg', logreg)])\n",
    "classifier4 = OneVsRestClassifier(pipe)\n",
    "classifier4.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_logreg = classifier4.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_logreg = classifier4.predict_proba(X_test)\n",
    "eigen_pr_curve.append((\"logreg\",y_test,y_score_logreg))\n",
    "\n",
    "\n",
    "linear_svm = LinearSVC(C=95.48139914999754,loss='hinge')\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                ('linear_svm', linear_svm)])\n",
    "classifier5 = OneVsRestClassifier(pipe)\n",
    "classifier5.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_linsvm = classifier5.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_linsvm = classifier5.predict_proba(X_test)\n",
    "eigen_pr_curve.append((\"linsvm\",y_test,y_score_linsvm))\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0,min_samples_leaf=1,max_depth=15,min_impurity_decrease=0.021318938975762092,criterion='entropy',max_features=10,\n",
    "                              max_leaf_nodes=None)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                ('tree', tree)])\n",
    "classifier6 = OneVsRestClassifier(pipe)\n",
    "classifier6.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_tree = classifier6.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_tree = classifier6.predict_proba(X_test)\n",
    "eigen_pr_curve.append((\"tree\",y_test,y_score_tree))\n",
    "\n",
    "\n",
    "forrest = RandomForestClassifier(random_state=0,min_samples_leaf=3,max_depth=10,n_estimators=387,class_weight='balanced',bootstrap=True)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                ('forrest', forrest)])\n",
    "classifier7 = OneVsRestClassifier(pipe)\n",
    "classifier7.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_forrest = classifier7.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_forrest = classifier7.predict_proba(X_test)\n",
    "eigen_pr_curve.append((\"forrest\",y_test,y_score_forrest))\n",
    "\n",
    "\n",
    "adaboost = AdaBoostClassifier(n_estimators=264,random_state=0,learning_rate=0.2131171118825734)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                ('adaboost', adaboost)])\n",
    "classifier8 = OneVsRestClassifier(pipe)\n",
    "classifier8.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_ada = classifier8.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_ada = classifier8.predict_proba(X_test)\n",
    "eigen_pr_curve.append((\"ada\",y_test,y_score_ada))\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                ('gnb', gnb)])\n",
    "classifier9 = OneVsRestClassifier(pipe)\n",
    "classifier9.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_gnb = classifier9.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_gnb = classifier9.predict_proba(X_test)\n",
    "eigen_pr_curve.append((\"gnb\",y_test,y_score_gnb))\n",
    "\n",
    "\n",
    "gpc = GaussianProcessClassifier(kernel=1.0*RBF(length_scale=0.840398547098756),random_state=0)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                ('gpc', gpc)])\n",
    "classifier10 = OneVsRestClassifier(pipe)\n",
    "classifier10.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_gpc = classifier10.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_gpc = classifier10.predict_proba(X_test)\n",
    "eigen_pr_curve.append((\"gpc\",y_test,y_score_gpc))\n",
    "\n",
    "\n",
    "ridge = RidgeClassifier()\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                ('ridge', ridge)])\n",
    "classifier11 = OneVsRestClassifier(pipe)\n",
    "classifier11.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_ridge = classifier11.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_ridge = classifier11.predict_proba(X_test)\n",
    "eigen_pr_curve.append((\"ridge\",y_test,y_score_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eigen_pr_curve.p', 'wb') as fp:\n",
    "    pickle.dump(eigen_pr_curve, fp, protocol=pickle.HIGHEST_PROTOCOL)#DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fisherfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_faces = []\n",
    "\n",
    "for face in faces:\n",
    "    flat_faces.append(face.reshape(-1))        \n",
    "flat_faces = np.array(flat_faces)\n",
    "labels=np.array(labels)     \n",
    "\n",
    "Y = label_binarize(labels, classes=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(flat_faces,Y,test_size=0.30,stratify=Y,shuffle=True,random_state = 42)\n",
    "\n",
    "pca = PCA(n_components=142, svd_solver='randomized',whiten=True)\n",
    "lda = LDA()\n",
    "\n",
    "svc=SVC(kernel='linear', class_weight='balanced',C=3.9241808801638385,gamma=96.58400875342846,degree=6)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda',lda),\n",
    "                ('svc', svc)])\n",
    "classifier1 = OneVsRestClassifier(pipe)\n",
    "classifier1.fit(X_train, y_train)\n",
    "y_score_svc = classifier1.decision_function(X_test)\n",
    "fisher_pr_curve.append((\"svc\",y_test,y_score_svc))\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=13,p=1,leaf_size=32)\n",
    "model = Pipeline([('pca', pca),\n",
    "                 ('lda',lda),\n",
    "                ('knn', knn)])\n",
    "classifier2 = OneVsRestClassifier(pipe)\n",
    "classifier2.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_knn = classifier2.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_knn = classifier2.predict_proba(X_test)\n",
    "fisher_pr_curve.append((\"knn\",y_test,y_score_knn))\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(solver='adam',hidden_layer_sizes=(417,469,290,194),alpha=0.011508598976828089,\n",
    "                    learning_rate='constant', activation='tanh',momentum=0.5812137485951651,verbose=False, early_stopping=True)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda',lda),\n",
    "                ('mlp', mlp)])\n",
    "classifier3 = OneVsRestClassifier(pipe)\n",
    "classifier3.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_mlp = classifier3.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_mlp = classifier3.predict_proba(X_test)\n",
    "fisher_pr_curve.append((\"mlp\",y_test,y_score_mlp))\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(C=26.23190488581573,solver='lbfgs',class_weight='balanced')\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda',lda),\n",
    "                ('logreg', logreg)])\n",
    "classifier4 = OneVsRestClassifier(pipe)\n",
    "classifier4.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_logreg = classifier4.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_logreg = classifier4.predict_proba(X_test)\n",
    "fisher_pr_curve.append((\"logreg\",y_test,y_score_logreg))\n",
    "\n",
    "\n",
    "linear_svm = LinearSVC(C=0.851388416540332,loss='hinge',class_weight='balanced',fit_intercept=False)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda', lda),\n",
    "                ('linear_svm', linear_svm)])\n",
    "classifier5 = OneVsRestClassifier(pipe)\n",
    "classifier5.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_linsvm = classifier5.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_linsvm = classifier5.predict_proba(X_test)\n",
    "fisher_pr_curve.append((\"linsvm\",y_test,y_score_linsvm))\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0,criterion='gini',min_impurity_decrease=0.03861521502801396,max_depth=19,min_samples_leaf=2,max_leaf_nodes=None)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda',lda),\n",
    "                ('tree', tree)])\n",
    "classifier6 = OneVsRestClassifier(pipe)\n",
    "classifier6.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_tree = classifier6.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_tree = classifier6.predict_proba(X_test)\n",
    "fisher_pr_curve.append((\"tree\",y_test,y_score_tree))\n",
    "\n",
    "\n",
    "forrest = RandomForestClassifier(random_state=0,max_depth=9,min_samples_leaf=3,n_estimators=241,class_weight='balanced',bootstrap=True)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda', lda),\n",
    "                ('forrest', forrest)])\n",
    "classifier7 = OneVsRestClassifier(pipe)\n",
    "classifier7.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_forrest = classifier7.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_forrest = classifier7.predict_proba(X_test)\n",
    "fisher_pr_curve.append((\"forrest\",y_test,y_score_forrest))\n",
    "\n",
    "\n",
    "adaboost = AdaBoostClassifier(n_estimators=174,random_state=0,learning_rate=0.28183708257574086)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda', lda),\n",
    "                ('adaboost', adaboost)])\n",
    "classifier8 = OneVsRestClassifier(pipe)\n",
    "classifier8.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_ada = classifier8.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_ada = classifier8.predict_proba(X_test)\n",
    "fisher_pr_curve.append((\"ada\",y_test,y_score_ada))\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('lda', lda),\n",
    "                ('gnb', gnb)])\n",
    "classifier9 = OneVsRestClassifier(pipe)\n",
    "classifier9.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_gnb = classifier9.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_gnb = classifier9.predict_proba(X_test)\n",
    "fisher_pr_curve.append((\"gnb\",y_test,y_score_gnb))\n",
    "\n",
    "\n",
    "gpc = GaussianProcessClassifier(kernel=1.0*RBF(length_scale=1.0687440294594166),random_state=0)\n",
    "pipe=Pipeline([('pca', pca),\n",
    "                ('lda',lda),\n",
    "                ('gpc', gpc)])\n",
    "classifier10 = OneVsRestClassifier(pipe)\n",
    "classifier10.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_gpc = classifier10.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_gpc = classifier10.predict_proba(X_test)\n",
    "fisher_pr_curve.append((\"gpc\",y_test,y_score_gpc))\n",
    "\n",
    "\n",
    "ridge = RidgeClassifier(alpha=0.5)\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                ('lda',lda),\n",
    "                ('ridge', ridge)])\n",
    "classifier11 = OneVsRestClassifier(pipe)\n",
    "classifier11.fit(X_train, y_train)\n",
    "try:\n",
    "    y_score_ridge = classifier11.decision_function(X_test)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_ridge = classifier11.predict_proba(X_test)\n",
    "fisher_pr_curve.append((\"ridge\",y_test,y_score_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fisher_pr_curve.p', 'wb') as fp:\n",
    "    pickle.dump(fisher_pr_curve, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "faces = np.array(faces)\n",
    "labels=np.array(labels)\n",
    "\n",
    "des_list = []\n",
    "\n",
    "#orb=cv2.ORB_create()\n",
    "#brisk = cv2.BRISK_create(30)\n",
    "#surf=cv2.xfeatures2d.SURF_create()\n",
    "sift = cv2.xfeatures2d.SIFT_create(nOctaveLayers=3, contrastThreshold=0.03, edgeThreshold=10, sigma=1.6)\n",
    "\n",
    "list_to_delete=[] \n",
    "\n",
    "print(\"Finding descriptors for \",len(faces),\" images\")\n",
    "t0 = time()\n",
    "for i,face in enumerate(faces):\n",
    "    image_path=datapath\n",
    "\n",
    "    #kpts, des = orb.detectAndCompute(im, None)\n",
    "    #kpts, des = brisk.detectAndCompute(im, None)\n",
    "    #kpts, des = surf.detectAndCompute(im, None)\n",
    "    kpts, des = sift.detectAndCompute(face, None)\n",
    "\n",
    "    if des is not None:\n",
    "        des_list.append((image_path, des))\n",
    "    else:\n",
    "        list_to_delete.append(i)\n",
    "            \n",
    "labels=np.array(labels)\n",
    "des_list=np.array(des_list)\n",
    "\n",
    "Y = label_binarize(labels, classes=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(des_list,Y,test_size=0.3,stratify=Y,shuffle=True,random_state = 42)\n",
    "\n",
    "descriptors = X_train[0][1]\n",
    "for image_path, descriptor in X_train[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "\n",
    "descriptors_float = descriptors.astype(float) \n",
    "\n",
    "k = 200\n",
    "voc, variance = kmeans(descriptors_float, k, 1)\n",
    "\n",
    "im_features = np.zeros((len(X_train), k), \"float32\")\n",
    "for i in range(len(X_train)):\n",
    "    words, distance = vq(X_train[i][1],voc)\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "\n",
    "nbr_occurences = np.sum( (im_features > 0) * 1, axis = 0)\n",
    "idf = np.array(np.log((1.0*len(X_train)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "stdSlr = StandardScaler().fit(im_features)\n",
    "im_features = stdSlr.transform(im_features)\n",
    "\n",
    "########################################\n",
    "svc=SVC(class_weight='balanced',C=68.05601024732132,gamma=19.032746691658865,kernel='linear',degree=3)    \n",
    "classifier1 = OneVsRestClassifier(svc)\n",
    "classifier1.fit(im_features,y_train)\n",
    "\n",
    "linsvc = LinearSVC(C=13.273988533706948,loss='hinge',class_weight=None,fit_intercept=True)    \n",
    "classifier2 = OneVsRestClassifier(linsvc)\n",
    "classifier2.fit(im_features,y_train)\n",
    "\n",
    "forrest = RandomForestClassifier(n_estimators = 290, random_state=30,max_depth=9,min_samples_leaf=2,class_weight='balanced',bootstrap=True)    \n",
    "classifier3 = OneVsRestClassifier(forrest)\n",
    "classifier3.fit(im_features,y_train)\n",
    "\n",
    "logreg = LogisticRegression(class_weight=None,C=81.37904643771212,solver='newton-cg')\n",
    "classifier4 = OneVsRestClassifier(logreg)\n",
    "classifier4.fit(im_features,y_train)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0,criterion='entropy',min_impurity_decrease=0.009033508409721459,max_depth=None,min_samples_leaf=5,\n",
    "                          max_leaf_nodes=7,max_features=None)    \n",
    "classifier5 = OneVsRestClassifier(tree)\n",
    "classifier5.fit(im_features,y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10,p=2,leaf_size=41)    \n",
    "classifier6 = OneVsRestClassifier(knn)\n",
    "classifier6.fit(im_features,y_train)\n",
    "\n",
    "mlp = MLPClassifier(solver='adam',hidden_layer_sizes=(453,498,225,316),alpha=0.03009184217630222, verbose=0, early_stopping=True,activation='tanh',momentum=0.43299330454632257,learning_rate='constant')    \n",
    "classifier7 = OneVsRestClassifier(mlp)\n",
    "classifier7.fit(im_features,y_train)\n",
    "\n",
    "adaboost = AdaBoostClassifier(random_state=0,n_estimators=248,learning_rate=0.10949478469869828)\n",
    "classifier8 = OneVsRestClassifier(adaboost)\n",
    "classifier8.fit(im_features,y_train)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "classifier9 = OneVsRestClassifier(gnb)\n",
    "classifier9.fit(im_features,y_train)\n",
    "\n",
    "gpc = GaussianProcessClassifier(kernel=1.0*RBF(length_scale=2.331930318829218),random_state=0)    \n",
    "classifier10 = OneVsRestClassifier(gpc)\n",
    "classifier10.fit(im_features,y_train)\n",
    "\n",
    "ridge = RidgeClassifier(alpha=0.5,solver='saga')\n",
    "classifier11 = OneVsRestClassifier(ridge)\n",
    "classifier11.fit(im_features,y_train)\n",
    "\n",
    "###########################################\n",
    "descriptors = X_test[0][1]\n",
    "for image_path, descriptor in X_test[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "\n",
    "test_features = np.zeros((len(X_test), k), \"float32\")\n",
    "for i in range(len(X_test)):\n",
    "    words, distance = vq(X_test[i][1],voc)\n",
    "    for w in words:\n",
    "        test_features[i][w] += 1\n",
    "\n",
    "nbr_occurences = np.sum( (test_features > 0) * 1, axis = 0)\n",
    "idf = np.array(np.log((1.0*len(X_test)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "test_features = stdSlr.transform(test_features)\n",
    "\n",
    "y_score_svc = classifier1.decision_function(test_features)\n",
    "sift_pr_curve.append((\"svc\",y_test,y_score_svc))\n",
    "\n",
    "try:\n",
    "    y_score_linsvc = classifier2.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_linsvc = classifier2.predict_proba(test_features)\n",
    "sift_pr_curve.append((\"linsvc\",y_test,y_score_linsvc))\n",
    "\n",
    "try:\n",
    "    y_score_forrest = classifier3.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_forrest = classifier3.predict_proba(test_features)\n",
    "sift_pr_curve.append((\"forrest\",y_test,y_score_forrest))\n",
    "\n",
    "try:\n",
    "    y_score_logreg = classifier4.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_logreg = classifier4.predict_proba(test_features)\n",
    "sift_pr_curve.append((\"logreg\",y_test,y_score_logreg))\n",
    "\n",
    "try:\n",
    "    y_score_tree = classifier5.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_tree = classifier5.predict_proba(test_features)\n",
    "sift_pr_curve.append((\"tree\",y_test,y_score_tree))\n",
    "\n",
    "try:\n",
    "    y_score_knn = classifier6.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_knn = classifier6.predict_proba(test_features)\n",
    "sift_pr_curve.append((\"knn\",y_test,y_score_knn))\n",
    "\n",
    "try:\n",
    "    y_score_mlp = classifier7.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_mlp = classifier7.predict_proba(test_features)\n",
    "sift_pr_curve.append((\"mlp\",y_test,y_score_mlp))\n",
    "\n",
    "try:\n",
    "    y_score_adaboost = classifier8.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_adaboost = classifier8.predict_proba(test_features)\n",
    "sift_pr_curve.append((\"adaboost\",y_test,y_score_adaboost))\n",
    "\n",
    "try:\n",
    "    y_score_gnb = classifier9.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_gnb = classifier9.predict_proba(test_features)\n",
    "sift_pr_curve.append((\"gnb\",y_test,y_score_gnb))\n",
    "\n",
    "try:\n",
    "    y_score_gpc = classifier10.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_gpc = classifier10.predict_proba(test_features)\n",
    "sift_pr_curve.append((\"gpc\",y_test,y_score_gpc))\n",
    "\n",
    "try:\n",
    "    y_score_ridge = classifier11.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_ridge = classifier11.predict_proba(test_features)\n",
    "sift_pr_curve.append((\"ridge\",y_test,y_score_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sift_pr_curve.p', 'wb') as fp:\n",
    "    pickle.dump(sift_pr_curve, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SURF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "faces = np.array(faces)\n",
    "labels=np.array(labels)\n",
    "\n",
    "des_list = []\n",
    "\n",
    "#orb=cv2.ORB_create()\n",
    "#brisk = cv2.BRISK_create(30)\n",
    "surf=cv2.xfeatures2d.SURF_create()\n",
    "#sift = cv2.xfeatures2d.SIFT_create(nOctaveLayers=3, contrastThreshold=0.03, edgeThreshold=10, sigma=1.6)\n",
    "\n",
    "list_to_delete=[] \n",
    "\n",
    "print(\"Finding descriptors for \",len(faces),\" images\")\n",
    "t0 = time()\n",
    "for i,face in enumerate(faces):\n",
    "    image_path=datapath\n",
    "    \n",
    "    #kpts, des = orb.detectAndCompute(im, None)\n",
    "    #kpts, des = brisk.detectAndCompute(im, None)\n",
    "    kpts, des = surf.detectAndCompute(face, None)\n",
    "    #kpts, des = sift.detectAndCompute(im, None)\n",
    "\n",
    "    if des is not None:\n",
    "        des_list.append((image_path, des))\n",
    "    else:\n",
    "        list_to_delete.append(i)\n",
    "labels=np.array(labels)\n",
    "des_list=np.array(des_list)\n",
    "\n",
    "Y = label_binarize(labels, classes=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(des_list,Y,test_size=0.3,stratify=Y,shuffle=True,random_state = 42)\n",
    "\n",
    "descriptors = X_train[0][1]\n",
    "for image_path, descriptor in X_train[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "\n",
    "descriptors_float = descriptors.astype(float) \n",
    "\n",
    "k = 200\n",
    "voc, variance = kmeans(descriptors_float, k, 1)\n",
    "\n",
    "im_features = np.zeros((len(X_train), k), \"float32\")\n",
    "for i in range(len(X_train)):\n",
    "    words, distance = vq(X_train[i][1],voc)\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "\n",
    "nbr_occurences = np.sum( (im_features > 0) * 1, axis = 0)\n",
    "idf = np.array(np.log((1.0*len(X_train)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "stdSlr = StandardScaler().fit(im_features)\n",
    "im_features = stdSlr.transform(im_features)\n",
    "\n",
    "########################################\n",
    "svc=SVC(class_weight='balanced',C=68.05601024732132,gamma=19.032746691658865,kernel='linear',degree=3)    \n",
    "classifier1 = OneVsRestClassifier(svc)\n",
    "classifier1.fit(im_features,y_train)\n",
    "\n",
    "linsvc = LinearSVC(C=13.273988533706948,loss='hinge',class_weight=None,fit_intercept=True)    \n",
    "classifier2 = OneVsRestClassifier(linsvc)\n",
    "classifier2.fit(im_features,y_train)\n",
    "\n",
    "forrest = RandomForestClassifier(n_estimators = 290, random_state=30,max_depth=9,min_samples_leaf=2,class_weight='balanced',bootstrap=True)    \n",
    "classifier3 = OneVsRestClassifier(forrest)\n",
    "classifier3.fit(im_features,y_train)\n",
    "\n",
    "logreg = LogisticRegression(class_weight=None,C=81.37904643771212,solver='newton-cg')\n",
    "classifier4 = OneVsRestClassifier(logreg)\n",
    "classifier4.fit(im_features,y_train)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0,criterion='entropy',min_impurity_decrease=0.009033508409721459,max_depth=None,min_samples_leaf=5,\n",
    "                          max_leaf_nodes=7,max_features=None)    \n",
    "classifier5 = OneVsRestClassifier(tree)\n",
    "classifier5.fit(im_features,y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10,p=2,leaf_size=41)    \n",
    "classifier6 = OneVsRestClassifier(knn)\n",
    "classifier6.fit(im_features,y_train)\n",
    "\n",
    "mlp = MLPClassifier(solver='adam',hidden_layer_sizes=(453,498,225,316),alpha=0.03009184217630222, verbose=0, early_stopping=True,activation='tanh',momentum=0.43299330454632257,learning_rate='constant')    \n",
    "classifier7 = OneVsRestClassifier(mlp)\n",
    "classifier7.fit(im_features,y_train)\n",
    "\n",
    "adaboost = AdaBoostClassifier(random_state=0,n_estimators=248,learning_rate=0.10949478469869828)\n",
    "classifier8 = OneVsRestClassifier(adaboost)\n",
    "classifier8.fit(im_features,y_train)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "classifier9 = OneVsRestClassifier(gnb)\n",
    "classifier9.fit(im_features,y_train)\n",
    "\n",
    "gpc = GaussianProcessClassifier(kernel=1.0*RBF(length_scale=2.331930318829218),random_state=0)    \n",
    "classifier10 = OneVsRestClassifier(gpc)\n",
    "classifier10.fit(im_features,y_train)\n",
    "\n",
    "ridge = RidgeClassifier(alpha=0.5,solver='saga')\n",
    "classifier11 = OneVsRestClassifier(ridge)\n",
    "classifier11.fit(im_features,y_train)\n",
    "\n",
    "###########################################\n",
    "descriptors = X_test[0][1]\n",
    "for image_path, descriptor in X_test[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "\n",
    "test_features = np.zeros((len(X_test), k), \"float32\")\n",
    "for i in range(len(X_test)):\n",
    "    words, distance = vq(X_test[i][1],voc)\n",
    "    for w in words:\n",
    "        test_features[i][w] += 1\n",
    "\n",
    "nbr_occurences = np.sum( (test_features > 0) * 1, axis = 0)\n",
    "idf = np.array(np.log((1.0*len(X_test)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "test_features = stdSlr.transform(test_features)\n",
    "\n",
    "y_score_svc = classifier1.decision_function(test_features)\n",
    "surf_pr_curve.append((\"svc\",y_test,y_score_svc))\n",
    "\n",
    "try:\n",
    "    y_score_linsvc = classifier2.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_linsvc = classifier2.predict_proba(test_features)\n",
    "surf_pr_curve.append((\"linsvc\",y_test,y_score_linsvc))\n",
    "\n",
    "try:\n",
    "    y_score_forrest = classifier3.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_forrest = classifier3.predict_proba(test_features)\n",
    "surf_pr_curve.append((\"forrest\",y_test,y_score_forrest))\n",
    "\n",
    "try:\n",
    "    y_score_logreg = classifier4.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_logreg = classifier4.predict_proba(test_features)\n",
    "surf_pr_curve.append((\"logreg\",y_test,y_score_logreg))\n",
    "\n",
    "try:\n",
    "    y_score_tree = classifier5.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_tree = classifier5.predict_proba(test_features)\n",
    "surf_pr_curve.append((\"tree\",y_test,y_score_tree))\n",
    "\n",
    "try:\n",
    "    y_score_knn = classifier6.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_knn = classifier6.predict_proba(test_features)\n",
    "surf_pr_curve.append((\"knn\",y_test,y_score_knn))\n",
    "\n",
    "try:\n",
    "    y_score_mlp = classifier7.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_mlp = classifier7.predict_proba(test_features)\n",
    "surf_pr_curve.append((\"mlp\",y_test,y_score_mlp))\n",
    "\n",
    "try:\n",
    "    y_score_adaboost = classifier8.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_adaboost = classifier8.predict_proba(test_features)\n",
    "surf_pr_curve.append((\"adaboost\",y_test,y_score_adaboost))\n",
    "\n",
    "try:\n",
    "    y_score_gnb = classifier9.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_gnb = classifier9.predict_proba(test_features)\n",
    "surf_pr_curve.append((\"gnb\",y_test,y_score_gnb))\n",
    "\n",
    "try:\n",
    "    y_score_gpc = classifier10.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_gpc = classifier10.predict_proba(test_features)\n",
    "surf_pr_curve.append((\"gpc\",y_test,y_score_gpc))\n",
    "\n",
    "try:\n",
    "    y_score_ridge = classifier11.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_ridge = classifier11.predict_proba(test_features)\n",
    "surf_pr_curve.append((\"ridge\",y_test,y_score_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('surf_pr_curve.p', 'wb') as fp:\n",
    "    pickle.dump(surf_pr_curve, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BRISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "faces = np.array(faces)\n",
    "labels=np.array(labels)\n",
    "\n",
    "des_list = []\n",
    "\n",
    "#orb=cv2.ORB_create()\n",
    "brisk = cv2.BRISK_create(30)\n",
    "#surf=cv2.xfeatures2d.SURF_create()\n",
    "#sift = cv2.xfeatures2d.SIFT_create(nOctaveLayers=3, contrastThreshold=0.03, edgeThreshold=10, sigma=1.6)\n",
    "\n",
    "list_to_delete=[] \n",
    "\n",
    "print(\"Finding descriptors for \",len(faces),\" images\")\n",
    "t0 = time()\n",
    "for i,face in enumerate(faces):\n",
    "    image_path=datapath\n",
    "\n",
    "    #kpts, des = orb.detectAndCompute(im, None)\n",
    "    kpts, des = brisk.detectAndCompute(face, None)\n",
    "    #kpts, des = surf.detectAndCompute(im, None)\n",
    "    #kpts, des = sift.detectAndCompute(im, None)\n",
    "\n",
    "    if des is not None:\n",
    "        des_list.append((image_path, des))\n",
    "    else:\n",
    "        list_to_delete.append(i)\n",
    "            \n",
    "new_faces = [j for i, j in enumerate(faces) if i not in list_to_delete]\n",
    "faces=new_faces\n",
    "\n",
    "new_labels = [j for i, j in enumerate(labels) if i not in list_to_delete]\n",
    "labels=new_labels\n",
    "\n",
    "labels=np.array(labels)\n",
    "des_list=np.array(des_list)\n",
    "\n",
    "Y = label_binarize(labels, classes=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(des_list,Y,test_size=0.3,stratify=Y,shuffle=True,random_state = 42)\n",
    "\n",
    "descriptors = X_train[0][1]\n",
    "for image_path, descriptor in X_train[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "\n",
    "descriptors_float = descriptors.astype(float) \n",
    "\n",
    "k = 200\n",
    "voc, variance = kmeans(descriptors_float, k, 1)\n",
    "\n",
    "im_features = np.zeros((len(X_train), k), \"float32\")\n",
    "for i in range(len(X_train)):\n",
    "    words, distance = vq(X_train[i][1],voc)\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "\n",
    "nbr_occurences = np.sum( (im_features > 0) * 1, axis = 0)\n",
    "idf = np.array(np.log((1.0*len(X_train)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "stdSlr = StandardScaler().fit(im_features)\n",
    "im_features = stdSlr.transform(im_features)\n",
    "\n",
    "########################################\n",
    "print(\"*\")\n",
    "svc=SVC(class_weight='balanced',C=68.05601024732132,gamma=19.032746691658865,kernel='linear',degree=3)    \n",
    "classifier1 = OneVsRestClassifier(svc)\n",
    "classifier1.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "linsvc = LinearSVC(C=13.273988533706948,loss='hinge',class_weight=None,fit_intercept=True)    \n",
    "classifier2 = OneVsRestClassifier(linsvc)\n",
    "classifier2.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "forrest = RandomForestClassifier(n_estimators = 290, random_state=30,max_depth=9,min_samples_leaf=2,class_weight='balanced',bootstrap=True)    \n",
    "classifier3 = OneVsRestClassifier(forrest)\n",
    "classifier3.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "logreg = LogisticRegression(class_weight=None,C=81.37904643771212,solver='newton-cg')\n",
    "classifier4 = OneVsRestClassifier(logreg)\n",
    "classifier4.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "tree = DecisionTreeClassifier(random_state=0,criterion='entropy',min_impurity_decrease=0.009033508409721459,max_depth=None,min_samples_leaf=5,\n",
    "                          max_leaf_nodes=7,max_features=None)    \n",
    "classifier5 = OneVsRestClassifier(tree)\n",
    "classifier5.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "knn = KNeighborsClassifier(n_neighbors=10,p=2,leaf_size=41)    \n",
    "classifier6 = OneVsRestClassifier(knn)\n",
    "classifier6.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "mlp = MLPClassifier(solver='adam',hidden_layer_sizes=(453,498,225,316),alpha=0.03009184217630222, verbose=0, early_stopping=True,activation='tanh',momentum=0.43299330454632257,learning_rate='constant')    \n",
    "classifier7 = OneVsRestClassifier(mlp)\n",
    "classifier7.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "adaboost = AdaBoostClassifier(random_state=0,n_estimators=248,learning_rate=0.10949478469869828)\n",
    "classifier8 = OneVsRestClassifier(adaboost)\n",
    "classifier8.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "gnb = GaussianNB()\n",
    "classifier9 = OneVsRestClassifier(gnb)\n",
    "classifier9.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "gpc = GaussianProcessClassifier(kernel=1.0*RBF(length_scale=2.331930318829218),random_state=0)    \n",
    "classifier10 = OneVsRestClassifier(gpc)\n",
    "classifier10.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "ridge = RidgeClassifier(alpha=0.5,solver='saga')\n",
    "classifier11 = OneVsRestClassifier(ridge)\n",
    "classifier11.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "###########################################\n",
    "descriptors = X_test[0][1]\n",
    "for image_path, descriptor in X_test[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "\n",
    "test_features = np.zeros((len(X_test), k), \"float32\")\n",
    "for i in range(len(X_test)):\n",
    "    words, distance = vq(X_test[i][1],voc)\n",
    "    for w in words:\n",
    "        test_features[i][w] += 1\n",
    "\n",
    "nbr_occurences = np.sum( (test_features > 0) * 1, axis = 0)\n",
    "idf = np.array(np.log((1.0*len(X_test)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "test_features = stdSlr.transform(test_features)\n",
    "\n",
    "y_score_svc = classifier1.decision_function(test_features)\n",
    "brisk_pr_curve.append((\"svc\",y_test,y_score_svc))\n",
    "\n",
    "try:\n",
    "    y_score_linsvc = classifier2.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_linsvc = classifier2.predict_proba(test_features)\n",
    "brisk_pr_curve.append((\"linsvc\",y_test,y_score_linsvc))\n",
    "\n",
    "try:\n",
    "    y_score_forrest = classifier3.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_forrest = classifier3.predict_proba(test_features)\n",
    "brisk_pr_curve.append((\"forrest\",y_test,y_score_forrest))\n",
    "\n",
    "try:\n",
    "    y_score_logreg = classifier4.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_logreg = classifier4.predict_proba(test_features)\n",
    "brisk_pr_curve.append((\"logreg\",y_test,y_score_logreg))\n",
    "\n",
    "try:\n",
    "    y_score_tree = classifier5.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_tree = classifier5.predict_proba(test_features)\n",
    "brisk_pr_curve.append((\"tree\",y_test,y_score_tree))\n",
    "\n",
    "try:\n",
    "    y_score_knn = classifier6.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_knn = classifier6.predict_proba(test_features)\n",
    "brisk_pr_curve.append((\"knn\",y_test,y_score_knn))\n",
    "\n",
    "try:\n",
    "    y_score_mlp = classifier7.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_mlp = classifier7.predict_proba(test_features)\n",
    "brisk_pr_curve.append((\"mlp\",y_test,y_score_mlp))\n",
    "\n",
    "try:\n",
    "    y_score_adaboost = classifier8.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_adaboost = classifier8.predict_proba(test_features)\n",
    "brisk_pr_curve.append((\"adaboost\",y_test,y_score_adaboost))\n",
    "\n",
    "try:\n",
    "    y_score_gnb = classifier9.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_gnb = classifier9.predict_proba(test_features)\n",
    "brisk_pr_curve.append((\"gnb\",y_test,y_score_gnb))\n",
    "\n",
    "try:\n",
    "    y_score_gpc = classifier10.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_gpc = classifier10.predict_proba(test_features)\n",
    "brisk_pr_curve.append((\"gpc\",y_test,y_score_gpc))\n",
    "\n",
    "try:\n",
    "    y_score_ridge = classifier11.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_ridge = classifier11.predict_proba(test_features)\n",
    "brisk_pr_curve.append((\"ridge\",y_test,y_score_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('brisk_pr_curvec.p', 'wb') as fp:\n",
    "    pickle.dump(brisk_pr_curve, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "faces = np.array(faces)\n",
    "labels=np.array(labels)\n",
    "\n",
    "des_list = []\n",
    "\n",
    "orb=cv2.ORB_create()\n",
    "#brisk = cv2.BRISK_create(30)\n",
    "#surf=cv2.xfeatures2d.SURF_create()\n",
    "#sift = cv2.xfeatures2d.SIFT_create(nOctaveLayers=3, contrastThreshold=0.03, edgeThreshold=10, sigma=1.6)\n",
    "\n",
    "list_to_delete=[] \n",
    "\n",
    "print(\"Finding descriptors for \",len(faces),\" images\")\n",
    "t0 = time()\n",
    "for i,face in enumerate(faces):\n",
    "    image_path=datapath\n",
    "    \n",
    "    kpts, des = orb.detectAndCompute(face, None)\n",
    "    #kpts, des = brisk.detectAndCompute(im, None)\n",
    "    #kpts, des = surf.detectAndCompute(im, None)\n",
    "    #kpts, des = sift.detectAndCompute(im, None)\n",
    "\n",
    "    if des is not None:\n",
    "        des_list.append((image_path, des))\n",
    "    else:\n",
    "        list_to_delete.append(i)\n",
    "        \n",
    "labels=np.array(labels)\n",
    "des_list=np.array(des_list)\n",
    "\n",
    "Y = label_binarize(labels, classes=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(des_list,Y,test_size=0.3,stratify=Y,shuffle=True,random_state = 42)\n",
    "\n",
    "descriptors = X_train[0][1]\n",
    "for image_path, descriptor in X_train[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "\n",
    "descriptors_float = descriptors.astype(float) \n",
    "\n",
    "k = 200\n",
    "voc, variance = kmeans(descriptors_float, k, 1)\n",
    "\n",
    "im_features = np.zeros((len(X_train), k), \"float32\")\n",
    "for i in range(len(X_train)):\n",
    "    words, distance = vq(X_train[i][1],voc)\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "\n",
    "nbr_occurences = np.sum( (im_features > 0) * 1, axis = 0)\n",
    "idf = np.array(np.log((1.0*len(X_train)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "stdSlr = StandardScaler().fit(im_features)\n",
    "im_features = stdSlr.transform(im_features)\n",
    "\n",
    "########################################\n",
    "print(\"*\")\n",
    "svc=SVC(class_weight='balanced',C=68.05601024732132,gamma=19.032746691658865,kernel='linear',degree=3)    \n",
    "classifier1 = OneVsRestClassifier(svc)\n",
    "classifier1.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "linsvc = LinearSVC(C=13.273988533706948,loss='hinge',class_weight=None,fit_intercept=True)    \n",
    "classifier2 = OneVsRestClassifier(linsvc)\n",
    "classifier2.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "forrest = RandomForestClassifier(n_estimators = 290, random_state=30,max_depth=9,min_samples_leaf=2,class_weight='balanced',bootstrap=True)    \n",
    "classifier3 = OneVsRestClassifier(forrest)\n",
    "classifier3.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "logreg = LogisticRegression(class_weight=None,C=81.37904643771212,solver='newton-cg')\n",
    "classifier4 = OneVsRestClassifier(logreg)\n",
    "classifier4.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "tree = DecisionTreeClassifier(random_state=0,criterion='entropy',min_impurity_decrease=0.009033508409721459,max_depth=None,min_samples_leaf=5,\n",
    "                          max_leaf_nodes=7,max_features=None)    \n",
    "classifier5 = OneVsRestClassifier(tree)\n",
    "classifier5.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "knn = KNeighborsClassifier(n_neighbors=10,p=2,leaf_size=41)    \n",
    "classifier6 = OneVsRestClassifier(knn)\n",
    "classifier6.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "mlp = MLPClassifier(solver='adam',hidden_layer_sizes=(453,498,225,316),alpha=0.03009184217630222, verbose=0, early_stopping=True,activation='tanh',momentum=0.43299330454632257,learning_rate='constant')    \n",
    "classifier7 = OneVsRestClassifier(mlp)\n",
    "classifier7.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "adaboost = AdaBoostClassifier(random_state=0,n_estimators=248,learning_rate=0.10949478469869828)\n",
    "classifier8 = OneVsRestClassifier(adaboost)\n",
    "classifier8.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "gnb = GaussianNB()\n",
    "classifier9 = OneVsRestClassifier(gnb)\n",
    "classifier9.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "gpc = GaussianProcessClassifier(kernel=1.0*RBF(length_scale=2.331930318829218),random_state=0)    \n",
    "classifier10 = OneVsRestClassifier(gpc)\n",
    "classifier10.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "ridge = RidgeClassifier(alpha=0.5,solver='saga')\n",
    "classifier11 = OneVsRestClassifier(ridge)\n",
    "classifier11.fit(im_features,y_train)\n",
    "print(\"*\")\n",
    "###########################################\n",
    "descriptors = X_test[0][1]\n",
    "for image_path, descriptor in X_test[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "\n",
    "test_features = np.zeros((len(X_test), k), \"float32\")\n",
    "for i in range(len(X_test)):\n",
    "    words, distance = vq(X_test[i][1],voc)\n",
    "    for w in words:\n",
    "        test_features[i][w] += 1\n",
    "\n",
    "nbr_occurences = np.sum( (test_features > 0) * 1, axis = 0)\n",
    "idf = np.array(np.log((1.0*len(X_test)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "test_features = stdSlr.transform(test_features)\n",
    "\n",
    "y_score_svc = classifier1.decision_function(test_features)\n",
    "orb_pr_curve.append((\"svc\",y_test,y_score_svc))\n",
    "\n",
    "try:\n",
    "    y_score_linsvc = classifier2.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_linsvc = classifier2.predict_proba(test_features)\n",
    "orb_pr_curve.append((\"linsvc\",y_test,y_score_linsvc))\n",
    "\n",
    "try:\n",
    "    y_score_forrest = classifier3.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_forrest = classifier3.predict_proba(test_features)\n",
    "orb_pr_curve.append((\"forrest\",y_test,y_score_forrest))\n",
    "\n",
    "try:\n",
    "    y_score_logreg = classifier4.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_logreg = classifier4.predict_proba(test_features)\n",
    "orb_pr_curve.append((\"logreg\",y_test,y_score_logreg))\n",
    "\n",
    "try:\n",
    "    y_score_tree = classifier5.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_tree = classifier5.predict_proba(test_features)\n",
    "orb_pr_curve.append((\"tree\",y_test,y_score_tree))\n",
    "\n",
    "try:\n",
    "    y_score_knn = classifier6.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_knn = classifier6.predict_proba(test_features)\n",
    "orb_pr_curve.append((\"knn\",y_test,y_score_knn))\n",
    "\n",
    "try:\n",
    "    y_score_mlp = classifier7.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_mlp = classifier7.predict_proba(test_features)\n",
    "orb_pr_curve.append((\"mlp\",y_test,y_score_mlp))\n",
    "\n",
    "try:\n",
    "    y_score_adaboost = classifier8.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_adaboost = classifier8.predict_proba(test_features)\n",
    "orb_pr_curve.append((\"adaboost\",y_test,y_score_adaboost))\n",
    "\n",
    "try:\n",
    "    y_score_gnb = classifier9.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_gnb = classifier9.predict_proba(test_features)\n",
    "orb_pr_curve.append((\"gnb\",y_test,y_score_gnb))\n",
    "\n",
    "try:\n",
    "    y_score_gpc = classifier10.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_gpc = classifier10.predict_proba(test_features)\n",
    "orb_pr_curve.append((\"gpc\",y_test,y_score_gpc))\n",
    "\n",
    "try:\n",
    "    y_score_ridge = classifier11.decision_function(test_features)\n",
    "except AttributeError:  # Python 3.x\n",
    "    y_score_ridge = classifier11.predict_proba(test_features)\n",
    "orb_pr_curve.append((\"ridge\",y_test,y_score_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('orb_pr_curve.p', 'wb') as fp:\n",
    "    pickle.dump(orb_pr_curve, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
